{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI-LABEL CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score,make_scorer,hamming_loss\n",
    "import sklearn\n",
    "\n",
    "from skmultilearn.problem_transform import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to read the right file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monitoring_start_month</th>\n",
       "      <th>monitoring_days</th>\n",
       "      <th>active_days</th>\n",
       "      <th>data_quality_score</th>\n",
       "      <th>reliability_score</th>\n",
       "      <th>car_use_score</th>\n",
       "      <th>driver_behavior_score</th>\n",
       "      <th>n_trips</th>\n",
       "      <th>fuel_costs</th>\n",
       "      <th>body_type</th>\n",
       "      <th>...</th>\n",
       "      <th>average_pause_time</th>\n",
       "      <th>max_pause_time</th>\n",
       "      <th>median_pause_time</th>\n",
       "      <th>percentage_start_home</th>\n",
       "      <th>percentage_start_office</th>\n",
       "      <th>average_trip_duration_sec</th>\n",
       "      <th>percentage_charger_nearby</th>\n",
       "      <th>percentage_charger_fast_nearby</th>\n",
       "      <th>percentage_charger_3F_nearby</th>\n",
       "      <th>ev_brands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>9.373888</td>\n",
       "      <td>4.692516</td>\n",
       "      <td>7.451583</td>\n",
       "      <td>6.467989</td>\n",
       "      <td>392</td>\n",
       "      <td>16625</td>\n",
       "      <td>VAN</td>\n",
       "      <td>...</td>\n",
       "      <td>5591.336735</td>\n",
       "      <td>133880</td>\n",
       "      <td>557.5</td>\n",
       "      <td>7.397959</td>\n",
       "      <td>4.591837</td>\n",
       "      <td>1098.109694</td>\n",
       "      <td>13.520408</td>\n",
       "      <td>5.867347</td>\n",
       "      <td>7.653061</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9.062229</td>\n",
       "      <td>6.138472</td>\n",
       "      <td>7.616548</td>\n",
       "      <td>5.732751</td>\n",
       "      <td>314</td>\n",
       "      <td>17664</td>\n",
       "      <td>VAN</td>\n",
       "      <td>...</td>\n",
       "      <td>6739.085987</td>\n",
       "      <td>147051</td>\n",
       "      <td>703.0</td>\n",
       "      <td>8.280255</td>\n",
       "      <td>0.318471</td>\n",
       "      <td>1308.401274</td>\n",
       "      <td>13.057325</td>\n",
       "      <td>6.687898</td>\n",
       "      <td>6.369427</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>8.950726</td>\n",
       "      <td>5.415178</td>\n",
       "      <td>7.771661</td>\n",
       "      <td>6.493076</td>\n",
       "      <td>249</td>\n",
       "      <td>11769</td>\n",
       "      <td>VAN</td>\n",
       "      <td>...</td>\n",
       "      <td>9403.775100</td>\n",
       "      <td>224802</td>\n",
       "      <td>606.0</td>\n",
       "      <td>9.638554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1075.341365</td>\n",
       "      <td>13.654618</td>\n",
       "      <td>5.622490</td>\n",
       "      <td>8.032129</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>9.003805</td>\n",
       "      <td>5.945673</td>\n",
       "      <td>7.027738</td>\n",
       "      <td>5.758369</td>\n",
       "      <td>789</td>\n",
       "      <td>17323</td>\n",
       "      <td>VAN</td>\n",
       "      <td>...</td>\n",
       "      <td>8688.593156</td>\n",
       "      <td>244481</td>\n",
       "      <td>606.0</td>\n",
       "      <td>9.632446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1317.195184</td>\n",
       "      <td>14.575412</td>\n",
       "      <td>7.984791</td>\n",
       "      <td>6.590621</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>8.851813</td>\n",
       "      <td>5.518089</td>\n",
       "      <td>6.905178</td>\n",
       "      <td>5.513861</td>\n",
       "      <td>266</td>\n",
       "      <td>19741</td>\n",
       "      <td>VAN</td>\n",
       "      <td>...</td>\n",
       "      <td>8229.680451</td>\n",
       "      <td>238754</td>\n",
       "      <td>552.0</td>\n",
       "      <td>9.022556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1374.330827</td>\n",
       "      <td>14.661654</td>\n",
       "      <td>8.646617</td>\n",
       "      <td>6.015038</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   monitoring_start_month  monitoring_days  active_days  data_quality_score  \\\n",
       "0                       7               31           30            9.373888   \n",
       "1                       6               30           27            9.062229   \n",
       "2                       5               31           26            8.950726   \n",
       "3                       3               92           78            9.003805   \n",
       "4                       4               30           25            8.851813   \n",
       "\n",
       "   reliability_score  car_use_score  driver_behavior_score  n_trips  \\\n",
       "0           4.692516       7.451583               6.467989      392   \n",
       "1           6.138472       7.616548               5.732751      314   \n",
       "2           5.415178       7.771661               6.493076      249   \n",
       "3           5.945673       7.027738               5.758369      789   \n",
       "4           5.518089       6.905178               5.513861      266   \n",
       "\n",
       "   fuel_costs body_type  ... average_pause_time  max_pause_time  \\\n",
       "0       16625       VAN  ...        5591.336735          133880   \n",
       "1       17664       VAN  ...        6739.085987          147051   \n",
       "2       11769       VAN  ...        9403.775100          224802   \n",
       "3       17323       VAN  ...        8688.593156          244481   \n",
       "4       19741       VAN  ...        8229.680451          238754   \n",
       "\n",
       "   median_pause_time  percentage_start_home  percentage_start_office  \\\n",
       "0              557.5               7.397959                 4.591837   \n",
       "1              703.0               8.280255                 0.318471   \n",
       "2              606.0               9.638554                 0.000000   \n",
       "3              606.0               9.632446                 0.000000   \n",
       "4              552.0               9.022556                 0.000000   \n",
       "\n",
       "   average_trip_duration_sec  percentage_charger_nearby  \\\n",
       "0                1098.109694                  13.520408   \n",
       "1                1308.401274                  13.057325   \n",
       "2                1075.341365                  13.654618   \n",
       "3                1317.195184                  14.575412   \n",
       "4                1374.330827                  14.661654   \n",
       "\n",
       "   percentage_charger_fast_nearby  percentage_charger_3F_nearby  ev_brands  \n",
       "0                        5.867347                      7.653061         []  \n",
       "1                        6.687898                      6.369427         []  \n",
       "2                        5.622490                      8.032129         []  \n",
       "3                        7.984791                      6.590621         []  \n",
       "4                        8.646617                      6.015038         []  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles = pd.read_csv('DATA/driving_profiles_cleared_MULTI_LABEL_18_1.csv')\n",
    "profiles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the column `ev_brands` to list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "profiles.ev_brands = profiles.ev_brands.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up we have to transform the column of `ev_brands` to a list of items of 0 or 1, where each index position defines a different car brand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nissan',\n",
       " 'Peugeot',\n",
       " 'Hyundai',\n",
       " 'Renault',\n",
       " 'Skoda',\n",
       " 'Honda',\n",
       " 'Mazda',\n",
       " 'Volkswagen',\n",
       " 'DS',\n",
       " 'BMW',\n",
       " 'Smart',\n",
       " 'Kia',\n",
       " 'Mini',\n",
       " 'Citroen',\n",
       " 'Tesla',\n",
       " 'Opel']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 0\n",
    "max_brands = []\n",
    "for recom in profiles.ev_brands: #iterating every profile\n",
    "    if len(recom) > max_length:\n",
    "        max_length = len(recom)\n",
    "        max_brands = recom\n",
    "        \n",
    "max_brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that there are 16 different brands for the EV cars. That means we create lists of 16 items for each profile where each item corresponds to a specific brand according to the above list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encoded_brands = []\n",
    "for recom in profiles.ev_brands: #iterating every profile\n",
    "    profile_brands = [0 for i in range(16)]\n",
    "    for brand in recom: #iterating through every brand\n",
    "        index_brand = max_brands.index(brand) #finding the index of the particular brand from the max_brands\n",
    "        profile_brands[index_brand] = 1\n",
    "    all_encoded_brands.append(np.asarray(profile_brands))\n",
    "target = np.array([item for item in all_encoded_brands]) \n",
    "profiles = profiles.drop(['ev_brands'], axis=1) #deleting column from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we have to create dummie variables for all the columns that have non continious numeric values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = pd.get_dummies(profiles, columns=['driver_name','body_type','monitoring_start_month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the new shape of the data, 797 rows and 347 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 157)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing column names for lightGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "profiles = profiles.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x)) #fix error lgb does not support json characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shuffle the data and separate the column we want to predict afterwards:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "profiles = profiles.sample(frac = 1, random_state=9) #shuffling data\n",
    "target = target.sample(frac=1, random_state=9) # target column shuffling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up we define the folds to be used for cross-validation after in order to ensure repeatability. We will use `leave one out` meaning each time the model is trained on N-1 observations and test it on the Nth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = KFold(profiles.shape[0], shuffle=True, random_state=123)\n",
    "fold_50 = KFold(50, shuffle=True, random_state=123)\n",
    "fold_10 = KFold(10, shuffle=True, random_state=123)\n",
    "fold_20 = KFold(20, shuffle=True, random_state=123)\n",
    "fold_5 = KFold(5, shuffle=True, random_state=123)\n",
    "fold_250 = KFold(250, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function to print the mean and standard deviation for a list of scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores):\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy classifier\n",
    "Let's try a dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.22330032119914348\n",
      "Standard Deviation: 0.3662692000213301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "scores = cross_val_score(dummy_classifier, profiles, target,\n",
    "                        cv=loo, n_jobs=-1, scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving\n",
    "### Binary Relevance\n",
    "First we will treat each label as a separate single binary classification problem with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different metrics that we can use:\n",
    "* Accuracy score metric calculates subset accuracy, meaning the predicted set of labels should exactly match with the true set of labels\n",
    "* Hamming loss metric is equal to the number of incorrect predictions divided by the total number of predictions. Since it is a loss metric, the smaller the metric the better the model\n",
    "\n",
    "Hamming loss gives a better overview of the general correctness of the model and that is why we will use that metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision trees\n",
    "We start with decision trees and gridsearchCV to find the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'classifier__criterion': ('gini','entropy'),\n",
    "              'classifier__splitter': ('best', 'random'),\n",
    "              'classifier__max_features':('sqrt',None,'log2'),\n",
    "              'classifier__class_weight':(None,'balanced'),\n",
    "              'classifier__max_depth':(None,20,50),\n",
    "              'classifier__min_samples_leaf':(1,3),\n",
    "              'classifier__ccp_alpha':(0,0.15, 0.3),\n",
    "              'classifier__min_impurity_decrease':(0, 0.15, 0.3)\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the decision tree classifier with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(DecisionTreeClassifier(random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up the grid search classifier is declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the existing data to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1296 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=7)]: Done 564 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=7)]: Done 1264 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=7)]: Done 2164 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=7)]: Done 3264 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=7)]: Done 3997 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=7)]: Done 5091 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=7)]: Done 6791 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=7)]: Done 8691 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=7)]: Done 10791 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=7)]: Done 12947 out of 12960 | elapsed:  5.1min remaining:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 12960 out of 12960 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=BinaryRelevance(classifier=DecisionTreeClassifier(random_state=7),\n",
       "                                       require_dense=[True, True]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'classifier__ccp_alpha': (0, 0.15, 0.3),\n",
       "                         'classifier__class_weight': (None, 'balanced'),\n",
       "                         'classifier__criterion': ('gini', 'entropy'),\n",
       "                         'classifier__max_depth': (None, 20, 50),\n",
       "                         'classifier__max_features': ('sqrt', None, 'log2'),\n",
       "                         'classifier__min_impurity_decrease': (0, 0.15, 0.3),\n",
       "                         'classifier__min_samples_leaf': (1, 3),\n",
       "                         'classifier__splitter': ('best', 'random')},\n",
       "             scoring=make_scorer(hamming_loss, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(profiles, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters calculated from grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__ccp_alpha': 0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'entropy',\n",
       " 'classifier__max_depth': None,\n",
       " 'classifier__max_features': None,\n",
       " 'classifier__min_impurity_decrease': 0,\n",
       " 'classifier__min_samples_leaf': 3,\n",
       " 'classifier__splitter': 'best'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best estimator in a new variable to use it for cross-validation after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average hamming loss of the best model calculated above by using LOO cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.07501338329764454\n",
      "Standard Deviation: 0.1283927934244304\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_tree, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest\n",
    "Now lets try random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (100, 150, 175, 200),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'class_weight':('balanced_subsample','balanced',None),\n",
    "              'max_features':('auto','sqrt','log2',None),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced')\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the forest classifier with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(RandomForestClassifier(random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up the grid search classifier is declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the existing data to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 512 candidates, totalling 5120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 62.5min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 81.6min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 111.8min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 154.4min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed: 183.7min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed: 210.5min\n",
      "[Parallel(n_jobs=7)]: Done 5120 out of 5120 | elapsed: 227.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=BinaryRelevance(classifier=RandomForestClassifier(random_state=7),\n",
       "                                       require_dense=[True, True]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'classifier__bootstrap': (True, False),\n",
       "                         'classifier__class_weight': (None, 'balanced'),\n",
       "                         'classifier__criterion': ('gini', 'entropy'),\n",
       "                         'classifier__max_features': ('auto', 'sqrt', 'log2',\n",
       "                                                      None),\n",
       "                         'classifier__n_estimators': (100, 150, 175, 200),\n",
       "                         'classifier__oob_score': (True, False),\n",
       "                         'classifier__warm_start': (True, False)},\n",
       "             scoring=make_scorer(hamming_loss, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(profiles, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters calculated from grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__bootstrap': True,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'entropy',\n",
       " 'classifier__max_features': None,\n",
       " 'classifier__n_estimators': 175,\n",
       " 'classifier__oob_score': True,\n",
       " 'classifier__warm_start': True}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best estimator in a new variable to use it for cross-validation after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest = gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average hamming loss of the best model calculated above by using LOO cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.05259635974304069\n",
      "Standard Deviation: 0.12116970432351964\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_forest, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra trees\n",
    "Now extra trees will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (50,75,100,125),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'max_features':('sqrt',None,'log2'),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced'),\n",
    "              'max_depth':(None,10)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the extra trees classifier with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(ExtraTreesClassifier(random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up the grid search classifier is declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the existing data to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 768 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 22.3min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=7)]: Done 4050 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=7)]: Done 5098 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=7)]: Done 6215 tasks      | elapsed: 64.0min\n",
      "[Parallel(n_jobs=7)]: Done 7410 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=7)]: Done 7680 out of 7680 | elapsed: 73.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=BinaryRelevance(classifier=ExtraTreesClassifier(random_state=7),\n",
       "                                       require_dense=[True, True]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'classifier__bootstrap': (True, False),\n",
       "                         'classifier__class_weight': (None, 'balanced'),\n",
       "                         'classifier__criterion': ('gini', 'entropy'),\n",
       "                         'classifier__max_depth': (None, 10),\n",
       "                         'classifier__max_features': ('sqrt', None, 'log2'),\n",
       "                         'classifier__n_estimators': (50, 75, 100, 125),\n",
       "                         'classifier__oob_score': (True, False),\n",
       "                         'classifier__warm_start': (True, False)},\n",
       "             scoring=make_scorer(hamming_loss, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(profiles, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters calculated from grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__bootstrap': False,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'entropy',\n",
       " 'classifier__max_depth': 10,\n",
       " 'classifier__max_features': None,\n",
       " 'classifier__n_estimators': 125,\n",
       " 'classifier__oob_score': False,\n",
       " 'classifier__warm_start': True}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best estimator in a new variable to use it for cross-validation after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_extra = gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average hamming loss of the best model calculated above by using LOO cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.04730995717344754\n",
      "Standard Deviation: 0.11312411944313217\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_extra, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "Next up LightGBM classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'boosting_type': ('gbdt', 'dart', 'goss','rf'),\n",
    "              'max_depth': (-1,-5,-10),\n",
    "              'learning_rate':(0.1, 0.3, 0.5),\n",
    "              'n_estimators':(100, 133,166, 200),\n",
    "              'class_weight': (None,'balanced'),\n",
    "              'min_child_weight':(1e-3,1e-4),\n",
    "              'min_child_samples':(20,30)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the lightGBM classifier with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BinaryRelevance(lgb.LGBMClassifier(random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up the grid search classifier is declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the existing data to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 38.7min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 50.6min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed: 92.6min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed: 122.5min\n",
      "[Parallel(n_jobs=7)]: Done 6036 tasks      | elapsed: 149.3min\n",
      "[Parallel(n_jobs=7)]: Done 7186 tasks      | elapsed: 156.7min\n",
      "[Parallel(n_jobs=7)]: Done 8436 tasks      | elapsed: 165.7min\n",
      "[Parallel(n_jobs=7)]: Done 11520 out of 11520 | elapsed: 166.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=BinaryRelevance(classifier=LGBMClassifier(random_state=7),\n",
       "                                       require_dense=[True, True]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'classifier__boosting_type': ('gbdt', 'dart', 'goss',\n",
       "                                                       'rf'),\n",
       "                         'classifier__class_weight': (None, 'balanced'),\n",
       "                         'classifier__learning_rate': (0.1, 0.3, 0.5),\n",
       "                         'classifier__max_depth': (-1, -5, -10),\n",
       "                         'classifier__min_child_samples': (20, 30),\n",
       "                         'classifier__min_child_weight': (0.001, 0.0001),\n",
       "                         'classifier__n_estimators': (100, 133, 166, 200)},\n",
       "             scoring=make_scorer(hamming_loss, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(profiles, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters calculated from grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__boosting_type': 'dart',\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__learning_rate': 0.5,\n",
       " 'classifier__max_depth': -1,\n",
       " 'classifier__min_child_samples': 30,\n",
       " 'classifier__min_child_weight': 0.0001,\n",
       " 'classifier__n_estimators': 200}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best estimator in a new variable to use it for cross-validation after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_light = gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average hamming loss of the best model calculated above by using LOO cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0485144539614561\n",
      "Standard Deviation: 0.11036200678987762\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_light, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "Next up xgboost classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 42.5min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 79.4min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 90.3min\n",
      "[Parallel(n_jobs=7)]: Done 1920 out of 1920 | elapsed: 92.7min finished\n",
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__base_score': 0.8, 'classifier__booster': 'dart', 'classifier__eta': 0.3, 'classifier__eval_metric': 'merror', 'classifier__max_depth': 10, 'classifier__objective': 'reg:logistic', 'classifier__validate_parameters': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.05072269807280514\n",
      "Standard Deviation: 0.11105339099649791\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "parameters = {'booster': ('dart', 'gblinear', 'gbtree'),\n",
    "              'validate_parameters': (True,False),\n",
    "              'objective':('reg:logistic','binary:hinge'),\n",
    "              'base_score':(0.5,0.8),\n",
    "              'eta':(0.3,0.75),\n",
    "              'max_depth':(6,10),\n",
    "              'eval_metric':('merror','mlogloss')\n",
    "              #'rate_drop':(0,0.4)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = BinaryRelevance(XGBClassifier(seed=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_xgb = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xgb, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "Also logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4320 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  74 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 543 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=7)]: Done 1373 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=7)]: Done 1766 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=7)]: Done 2846 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=7)]: Done 4033 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=7)]: Done 5306 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=7)]: Done 6775 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=7)]: Done 8789 tasks      | elapsed: 52.3min\n",
      "[Parallel(n_jobs=7)]: Done 10786 tasks      | elapsed: 61.4min\n",
      "[Parallel(n_jobs=7)]: Done 13101 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=7)]: Done 15576 tasks      | elapsed: 85.7min\n",
      "[Parallel(n_jobs=7)]: Done 18264 tasks      | elapsed: 101.7min\n",
      "[Parallel(n_jobs=7)]: Done 20923 tasks      | elapsed: 118.6min\n",
      "[Parallel(n_jobs=7)]: Done 24298 tasks      | elapsed: 134.8min\n",
      "[Parallel(n_jobs=7)]: Done 27628 tasks      | elapsed: 150.7min\n",
      "[Parallel(n_jobs=7)]: Done 31163 tasks      | elapsed: 170.9min\n",
      "[Parallel(n_jobs=7)]: Done 34812 tasks      | elapsed: 192.3min\n",
      "[Parallel(n_jobs=7)]: Done 38686 tasks      | elapsed: 212.6min\n",
      "[Parallel(n_jobs=7)]: Done 42582 tasks      | elapsed: 232.4min\n",
      "[Parallel(n_jobs=7)]: Done 43200 out of 43200 | elapsed: 234.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 1.2, 'classifier__class_weight': None, 'classifier__fit_intercept': False, 'classifier__intercept_scaling': 0.8, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'classifier__tol': 0.001, 'classifier__warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.06684957173447538\n",
      "Standard Deviation: 0.137102739789716\n"
     ]
    }
   ],
   "source": [
    "parameters = {'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n",
    "              'tol': (1e-3, 1e-4, 1e-5),\n",
    "              'C':(0.8, 1 , 1.2),\n",
    "              'fit_intercept':(True,False),\n",
    "              'intercept_scaling': (0.8, 1, 1.2),\n",
    "              'class_weight':('balanced',None),\n",
    "              'solver':('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "              #'multi_class':('auto', 'ovr', 'multinomial'),\n",
    "              'warm_start':(True, False)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = BinaryRelevance(LogisticRegression(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_logistic = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_logistic, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Chains\n",
    "Now we will try classifier chains. In classifier chains, the first classifier is trained just on the input data and then each next classifier is trained on the input space and all the previous classifiers in the chain\n",
    "#### Decision trees\n",
    "We will start with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'classifier__criterion': ('gini','entropy'),\n",
    "              'classifier__splitter': ('best', 'random'),\n",
    "              'classifier__max_features':('sqrt',None,'log2'),\n",
    "              'classifier__class_weight':(None,'balanced'),\n",
    "              'classifier__max_depth':(None,20,50),\n",
    "              'classifier__min_samples_leaf':(1,3,6),\n",
    "              'classifier__ccp_alpha':(0,0.15, 0.3),\n",
    "              'classifier__min_impurity_decrease':(0, 0.15, 0.3)\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the decision tree classifier with binary relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ClassifierChain(DecisionTreeClassifier(random_state=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up the grid search classifier is declared:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit the model on the existing data to find the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1944 candidates, totalling 19440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=7)]: Done 295 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=7)]: Done 795 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=7)]: Done 1495 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=7)]: Done 2395 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=7)]: Done 3495 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=7)]: Done 4795 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=7)]: Done 6295 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=7)]: Done 7995 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=7)]: Done 9895 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=7)]: Done 11995 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=7)]: Done 14295 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=7)]: Done 16795 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=7)]: Done 19427 out of 19440 | elapsed:  6.2min remaining:    0.2s\n",
      "[Parallel(n_jobs=7)]: Done 19440 out of 19440 | elapsed:  6.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=ClassifierChain(classifier=DecisionTreeClassifier(random_state=7),\n",
       "                                       require_dense=[True, True]),\n",
       "             n_jobs=7,\n",
       "             param_grid={'classifier__ccp_alpha': (0, 0.15, 0.3),\n",
       "                         'classifier__class_weight': (None, 'balanced'),\n",
       "                         'classifier__criterion': ('gini', 'entropy'),\n",
       "                         'classifier__max_depth': (None, 20, 50),\n",
       "                         'classifier__max_features': ('sqrt', None, 'log2'),\n",
       "                         'classifier__min_impurity_decrease': (0, 0.15, 0.3),\n",
       "                         'classifier__min_samples_leaf': (1, 3, 6),\n",
       "                         'classifier__splitter': ('best', 'random')},\n",
       "             scoring=make_scorer(hamming_loss, greater_is_better=False),\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.fit(profiles, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters calculated from grid-search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__ccp_alpha': 0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__criterion': 'gini',\n",
       " 'classifier__max_depth': None,\n",
       " 'classifier__max_features': None,\n",
       " 'classifier__min_impurity_decrease': 0,\n",
       " 'classifier__min_samples_leaf': 6,\n",
       " 'classifier__splitter': 'best'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the best estimator in a new variable to use it for cross-validation after: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = gs_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average hamming loss of the best model calculated above by using LOO cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.07508029978586724\n",
      "Standard Deviation: 0.15558824612221722\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(best_tree, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "Also logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4320 candidates, totalling 43200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  38 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=7)]: Done 326 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=7)]: Done 590 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=7)]: Done 1563 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=7)]: Done 2622 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=7)]: Done 3781 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=7)]: Done 5089 tasks      | elapsed: 25.8min\n",
      "[Parallel(n_jobs=7)]: Done 6476 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=7)]: Done 8422 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=7)]: Done 10194 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=7)]: Done 12532 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=7)]: Done 15166 tasks      | elapsed: 68.0min\n",
      "[Parallel(n_jobs=7)]: Done 18008 tasks      | elapsed: 83.8min\n",
      "[Parallel(n_jobs=7)]: Done 20846 tasks      | elapsed: 94.9min\n",
      "[Parallel(n_jobs=7)]: Done 24228 tasks      | elapsed: 110.1min\n",
      "[Parallel(n_jobs=7)]: Done 27983 tasks      | elapsed: 124.4min\n",
      "[Parallel(n_jobs=7)]: Done 31558 tasks      | elapsed: 143.7min\n",
      "[Parallel(n_jobs=7)]: Done 35233 tasks      | elapsed: 157.7min\n",
      "[Parallel(n_jobs=7)]: Done 39015 tasks      | elapsed: 177.2min\n",
      "[Parallel(n_jobs=7)]: Done 43200 out of 43200 | elapsed: 190.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 1.2, 'classifier__class_weight': None, 'classifier__fit_intercept': False, 'classifier__intercept_scaling': 0.8, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear', 'classifier__tol': 0.001, 'classifier__warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.06510974304068523\n",
      "Standard Deviation: 0.15143644825505279\n"
     ]
    }
   ],
   "source": [
    "parameters = {'penalty': ('l1', 'l2', 'elasticnet', 'none'),\n",
    "              'tol': (1e-3, 1e-4, 1e-5),\n",
    "              'C':(0.8, 1 , 1.2),\n",
    "              'fit_intercept':(True,False),\n",
    "              'intercept_scaling': (0.8, 1, 1.2),\n",
    "              'class_weight':('balanced',None),\n",
    "              'solver':('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'),\n",
    "              #'multi_class':('auto', 'ovr', 'multinomial'),\n",
    "              'warm_start':(True, False)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = ClassifierChain(LogisticRegression(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_logistic = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_logistic, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Random forest\n",
    "Now lets try random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 256 candidates, totalling 2560 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 79.0min\n",
      "[Parallel(n_jobs=7)]: Done 2560 out of 2560 | elapsed: 86.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__bootstrap': True, 'classifier__class_weight': None, 'classifier__criterion': 'entropy', 'classifier__max_features': None, 'classifier__n_estimators': 150, 'classifier__oob_score': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.05815042826552463\n",
      "Standard Deviation: 0.15095382362870088\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (100, 150, 175, 200),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'class_weight':('balanced_subsample','balanced',None),\n",
    "              'max_features':('auto','sqrt','log2',None),\n",
    "              #'warm_start':(True,False), True does not work\n",
    "              'class_weight':(None,'balanced')\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = ClassifierChain(RandomForestClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_forest = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_forest, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra trees\n",
    "Now lets try extratrees classifier. The steps are the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 768 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2880 fits failed out of a total of 7680.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "960 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\cc.py\", line 154, in fit\n",
      "    self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 486, in fit\n",
      "    self._set_oob_score_and_attributes(X, y)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 725, in _set_oob_score_and_attributes\n",
      "    self.oob_decision_function_ = super()._compute_oob_predictions(X, y)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 554, in _compute_oob_predictions\n",
      "    y_pred = self._get_oob_predictions(estimator, X[unsampled_indices, :])\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 703, in _get_oob_predictions\n",
      "    y_pred = tree.predict_proba(X, check_input=False)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 971, in predict_proba\n",
      "    X = self._validate_X_predict(X, check_input)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 440, in _validate_X_predict\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 400, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 158 features, but ExtraTreeClassifier is expecting 157 features as input.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1920 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skmultilearn\\problem_transform\\cc.py\", line 154, in fit\n",
      "    self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n",
      "  File \"C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 411, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan -0.07489133         nan -0.07489133         nan -0.07079401\n",
      "         nan -0.07079401         nan -0.06957933         nan -0.06957933\n",
      "         nan -0.06984743         nan -0.06984743         nan -0.05706217\n",
      "         nan -0.05706217         nan -0.05613061         nan -0.05613061\n",
      "         nan -0.0573267          nan -0.0573267          nan -0.05685984\n",
      "         nan -0.05685984         nan -0.07051876         nan -0.07051876\n",
      "         nan -0.07198081         nan -0.07198081         nan -0.07044655\n",
      "         nan -0.07044655         nan -0.0681566          nan -0.0681566\n",
      "         nan -0.07780757         nan -0.07780757         nan -0.07266143\n",
      "         nan -0.07266143         nan -0.0748084          nan -0.0748084\n",
      "         nan -0.07616178         nan -0.07616178         nan -0.0592077\n",
      "         nan -0.0592077          nan -0.06026581         nan -0.06026581\n",
      "         nan -0.059533           nan -0.059533           nan -0.05940503\n",
      "         nan -0.05940503         nan -0.08525009         nan -0.08525009\n",
      "         nan -0.084375           nan -0.084375           nan -0.08478395\n",
      "         nan -0.08478395         nan -0.08544812         nan -0.08544812\n",
      "         nan -0.06822237         nan -0.06822237         nan -0.06856412\n",
      "         nan -0.06856412         nan -0.06762183         nan -0.06762183\n",
      "         nan -0.06742307         nan -0.06742307         nan -0.05714224\n",
      "         nan -0.05714224         nan -0.05767845         nan -0.05767845\n",
      "         nan -0.0549245          nan -0.0549245          nan -0.05774637\n",
      "         nan -0.05774637         nan -0.07580645         nan -0.07580645\n",
      "         nan -0.07447023         nan -0.07447023         nan -0.0739948\n",
      "         nan -0.0739948          nan -0.07327628         nan -0.07327628\n",
      "         nan -0.08321108         nan -0.08321108         nan -0.08043139\n",
      "         nan -0.08043139         nan -0.07780614         nan -0.07780614\n",
      "         nan -0.07662434         nan -0.07662434         nan -0.058279\n",
      "         nan -0.058279           nan -0.05545427         nan -0.05545427\n",
      "         nan -0.05725306         nan -0.05725306         nan -0.05619423\n",
      "         nan -0.05619423         nan -0.08062586         nan -0.08062586\n",
      "         nan -0.08552891         nan -0.08552891         nan -0.08378303\n",
      "         nan -0.08378303         nan -0.08385524         nan -0.08385524\n",
      "         nan -0.07581074         nan -0.07581074         nan -0.0693005\n",
      "         nan -0.0693005          nan -0.07178706         nan -0.07178706\n",
      "         nan -0.07239405         nan -0.07239405         nan -0.0597339\n",
      "         nan -0.0597339          nan -0.05974176         nan -0.05974176\n",
      "         nan -0.05886024         nan -0.05886024         nan -0.05832618\n",
      "         nan -0.05832618         nan -0.07554764         nan -0.07554764\n",
      "         nan -0.07547257         nan -0.07547257         nan -0.07281086\n",
      "         nan -0.07281086         nan -0.07674874         nan -0.07674874\n",
      "         nan -0.08585707         nan -0.08585707         nan -0.08278926\n",
      "         nan -0.08278926         nan -0.08211007         nan -0.08211007\n",
      "         nan -0.08165108         nan -0.08165108         nan -0.06006134\n",
      "         nan -0.06006134         nan -0.05966884         nan -0.05966884\n",
      "         nan -0.0615334          nan -0.0615334          nan -0.05965812\n",
      "         nan -0.05965812         nan -0.10392144         nan -0.10392144\n",
      "         nan -0.1015121          nan -0.1015121          nan -0.09757779\n",
      "         nan -0.09757779         nan -0.10264885         nan -0.10264885\n",
      "         nan -0.07017058         nan -0.07017058         nan -0.06849691\n",
      "         nan -0.06849691         nan -0.07124013         nan -0.07124013\n",
      "         nan -0.07177777         nan -0.07177777         nan -0.06022506\n",
      "         nan -0.06022506         nan -0.05800446         nan -0.05800446\n",
      "         nan -0.05772921         nan -0.05772921         nan -0.05892888\n",
      "         nan -0.05892888         nan -0.07477837         nan -0.07477837\n",
      "         nan -0.07042796         nan -0.07042796         nan -0.0709656\n",
      "         nan -0.0709656          nan -0.07162978         nan -0.07162978\n",
      "         nan -0.08648622         nan -0.08648622         nan -0.08469172\n",
      "         nan -0.08469172         nan -0.0810634          nan -0.0810634\n",
      "         nan -0.0806516          nan -0.0806516          nan -0.05794798\n",
      "         nan -0.05794798         nan -0.05986902         nan -0.05986902\n",
      "         nan -0.05787148         nan -0.05787148         nan -0.06006563\n",
      "         nan -0.06006563         nan -0.10493022         nan -0.10493022\n",
      "         nan -0.10553935         nan -0.10553935         nan -0.10326942\n",
      "         nan -0.10326942         nan -0.10271891         nan -0.10271891\n",
      "         nan         nan         nan -0.06309054         nan         nan\n",
      "         nan -0.06195593         nan         nan         nan -0.06288535\n",
      "         nan         nan         nan -0.062964           nan         nan\n",
      "         nan -0.05644232         nan         nan         nan -0.05617207\n",
      "         nan         nan         nan -0.0550918          nan         nan\n",
      "         nan -0.05536062         nan         nan         nan -0.07051519\n",
      "         nan         nan         nan -0.06722432         nan         nan\n",
      "         nan -0.06802791         nan         nan         nan -0.06742593\n",
      "         nan         nan         nan -0.07098776         nan         nan\n",
      "         nan -0.07031715         nan         nan         nan -0.07252988\n",
      "         nan         nan         nan -0.07314545         nan         nan\n",
      "         nan -0.05777282         nan         nan         nan -0.05737317\n",
      "         nan         nan         nan -0.05676762         nan         nan\n",
      "         nan -0.05548573         nan         nan         nan -0.08719758\n",
      "         nan         nan         nan -0.08760581         nan         nan\n",
      "         nan -0.08572981         nan         nan         nan -0.08566332\n",
      "         nan         nan         nan -0.06650724         nan         nan\n",
      "         nan -0.06631349         nan         nan         nan -0.0641751\n",
      "         nan         nan         nan -0.06422944         nan         nan\n",
      "         nan -0.0547951          nan         nan         nan -0.05431323\n",
      "         nan         nan         nan -0.05338023         nan         nan\n",
      "         nan -0.05405514         nan         nan         nan -0.06903169\n",
      "         nan         nan         nan -0.07065746         nan         nan\n",
      "         nan -0.06623341         nan         nan         nan -0.06682967\n",
      "         nan         nan         nan -0.07462037         nan         nan\n",
      "         nan -0.07341212         nan         nan         nan -0.07414136\n",
      "         nan         nan         nan -0.0750765          nan         nan\n",
      "         nan -0.05513398         nan         nan         nan -0.05445765\n",
      "         nan         nan         nan -0.05372054         nan         nan\n",
      "         nan -0.0533166          nan         nan         nan -0.08544598\n",
      "         nan         nan         nan -0.08197066         nan         nan\n",
      "         nan -0.08109414         nan         nan         nan -0.08330474\n",
      "         nan         nan         nan -0.07156901         nan         nan\n",
      "         nan -0.06823596         nan         nan         nan -0.0695107\n",
      "         nan         nan         nan -0.06944993         nan         nan\n",
      "         nan -0.06039307         nan         nan         nan -0.05838052\n",
      "         nan         nan         nan -0.05851636         nan         nan\n",
      "         nan -0.05771277         nan         nan         nan -0.06804007\n",
      "         nan         nan         nan -0.06708276         nan         nan\n",
      "         nan -0.06770333         nan         nan         nan -0.06662735\n",
      "         nan         nan         nan -0.086715           nan         nan\n",
      "         nan -0.08671571         nan         nan         nan -0.08664922\n",
      "         nan         nan         nan -0.08925732         nan         nan\n",
      "         nan -0.06039665         nan         nan         nan -0.06006492\n",
      "         nan         nan         nan -0.05986187         nan         nan\n",
      "         nan -0.05972961         nan         nan         nan -0.10219558\n",
      "         nan         nan         nan -0.09985058         nan         nan\n",
      "         nan -0.09984271         nan         nan         nan -0.10133479\n",
      "         nan         nan         nan -0.06638427         nan         nan\n",
      "         nan -0.06550346         nan         nan         nan -0.06583519\n",
      "         nan         nan         nan -0.06616978         nan         nan\n",
      "         nan -0.05758694         nan         nan         nan -0.05745467\n",
      "         nan         nan         nan -0.05892244         nan         nan\n",
      "         nan -0.05872655         nan         nan         nan -0.07158545\n",
      "         nan         nan         nan -0.06435455         nan         nan\n",
      "         nan -0.06476207         nan         nan         nan -0.06449397\n",
      "         nan         nan         nan -0.09245096         nan         nan\n",
      "         nan -0.08708176         nan         nan         nan -0.08294941\n",
      "         nan         nan         nan -0.08374728         nan         nan\n",
      "         nan -0.05618637         nan         nan         nan -0.05798873\n",
      "         nan         nan         nan -0.05770919         nan         nan\n",
      "         nan -0.05797729         nan         nan         nan -0.10261239\n",
      "         nan         nan         nan -0.1026131          nan         nan\n",
      "         nan -0.1009573          nan         nan         nan -0.10281257]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__bootstrap': False, 'classifier__class_weight': None, 'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': None, 'classifier__n_estimators': 125, 'classifier__oob_score': False, 'classifier__warm_start': False}\n",
      "Mean: -0.05293094218415417\n",
      "Standard Deviation: 0.1355786346092023\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (50,75,100,125),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'max_features':('sqrt',None,'log2'),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced'),\n",
    "              'max_depth':(None,10)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = ClassifierChain(ExtraTreesClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_extra = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_extra, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  LightGBM\n",
    "Now lightgbm classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 65.2min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed: 95.0min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed: 130.1min\n",
      "[Parallel(n_jobs=7)]: Done 6036 tasks      | elapsed: 160.2min\n",
      "[Parallel(n_jobs=7)]: Done 7186 tasks      | elapsed: 168.8min\n",
      "[Parallel(n_jobs=7)]: Done 8436 tasks      | elapsed: 179.9min\n",
      "[Parallel(n_jobs=7)]: Done 11520 out of 11520 | elapsed: 181.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "Finished loading model, total used 225 iterations\n",
      "{'classifier__boosting_type': 'dart', 'classifier__class_weight': None, 'classifier__learning_rate': 0.5, 'classifier__max_depth': -1, 'classifier__min_child_samples': 30, 'classifier__min_child_weight': 0.0001, 'classifier__n_estimators': 225}\n",
      "--------------------------------------------\n",
      "Mean: -0.04898286937901499\n",
      "Standard Deviation: 0.12406490161850049\n"
     ]
    }
   ],
   "source": [
    "parameters = {'boosting_type': ('gbdt', 'dart', 'goss','rf'),\n",
    "              'max_depth': (-1,-5,-10),\n",
    "              'learning_rate':(0.1, 0.3, 0.5),\n",
    "              'n_estimators':(100, 150, 200,225),\n",
    "              'class_weight': (None,'balanced'),\n",
    "              'min_child_weight':(1e-3,1e-4),\n",
    "              'min_child_samples':(20,30)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = ClassifierChain(lgb.LGBMClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_light = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_light, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "Now xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 41.1min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 45.7min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 97.0min\n",
      "[Parallel(n_jobs=7)]: Done 1920 out of 1920 | elapsed: 99.2min finished\n",
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__base_score': 0.5, 'classifier__booster': 'dart', 'classifier__eta': 0.75, 'classifier__eval_metric': 'merror', 'classifier__max_depth': 6, 'classifier__objective': 'reg:logistic', 'classifier__validate_parameters': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.05580835117773019\n",
      "Standard Deviation: 0.13754156348590227\n"
     ]
    }
   ],
   "source": [
    "parameters = {'booster': ('dart', 'gblinear', 'gbtree'),\n",
    "              'validate_parameters': (True,False),\n",
    "              'objective':('reg:logistic','binary:hinge'),\n",
    "              'base_score':(0.5,0.8),\n",
    "              'eta':(0.3,0.75),\n",
    "              'max_depth':(6,10),\n",
    "              'eval_metric':('merror','mlogloss')\n",
    "              #'rate_drop':(0,0.4)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = ClassifierChain(XGBClassifier(seed=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_xgboost = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_xgboost, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Powerset\n",
    "The problem is transformed into a multi-class problem with one multi-class classifier that is trained on all unique label combinations found in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 768 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=7)]: Done 4134 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=7)]: Done 5539 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=7)]: Done 7023 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=7)]: Done 7680 out of 7680 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__bootstrap': False, 'classifier__class_weight': None, 'classifier__criterion': 'entropy', 'classifier__max_depth': 10, 'classifier__max_features': None, 'classifier__n_estimators': 100, 'classifier__oob_score': False, 'classifier__warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.056076017130620985\n",
      "Standard Deviation: 0.14437811929306865\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (50,75,100,125),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'max_features':('sqrt',None,'log2'),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced'),\n",
    "              'max_depth':(None,10)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = LabelPowerset(ExtraTreesClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_extra = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_extra, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 512 candidates, totalling 5120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=7)]: Done 3256 tasks      | elapsed: 48.9min\n",
      "[Parallel(n_jobs=7)]: Done 4106 tasks      | elapsed: 61.1min\n",
      "[Parallel(n_jobs=7)]: Done 5056 tasks      | elapsed: 83.4min\n",
      "[Parallel(n_jobs=7)]: Done 5120 out of 5120 | elapsed: 89.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__bootstrap': True, 'classifier__class_weight': None, 'classifier__criterion': 'gini', 'classifier__max_features': None, 'classifier__n_estimators': 100, 'classifier__oob_score': True, 'classifier__warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.05968950749464668\n",
      "Standard Deviation: 0.15453571570151853\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (100, 150, 175, 200),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'class_weight':('balanced_subsample','balanced',None),\n",
    "              'max_features':('auto','sqrt','log2',None),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced')\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = LabelPowerset(RandomForestClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_forest = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_forest, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1152 candidates, totalling 11520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed: 111.3min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed: 150.6min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed: 233.1min\n",
      "[Parallel(n_jobs=7)]: Done 6036 tasks      | elapsed: 249.5min\n",
      "[Parallel(n_jobs=7)]: Done 7186 tasks      | elapsed: 263.9min\n",
      "[Parallel(n_jobs=7)]: Done 8436 tasks      | elapsed: 283.6min\n",
      "[Parallel(n_jobs=7)]: Done 11520 out of 11520 | elapsed: 285.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__boosting_type': 'gbdt', 'classifier__class_weight': None, 'classifier__learning_rate': 0.1, 'classifier__max_depth': -1, 'classifier__min_child_samples': 20, 'classifier__min_child_weight': 0.001, 'classifier__n_estimators': 225}\n",
      "--------------------------------------------\n",
      "Mean: -0.06336991434689508\n",
      "Standard Deviation: 0.15722818884284742\n"
     ]
    }
   ],
   "source": [
    "parameters = {'boosting_type': ('gbdt', 'dart', 'goss','rf'),\n",
    "              'max_depth': (-1,-5,-10),\n",
    "              'learning_rate':(0.1, 0.3, 0.5),\n",
    "              'n_estimators':(100, 150, 200,225),\n",
    "              'class_weight': (None,'balanced'),\n",
    "              'min_child_weight':(1e-3,1e-4),\n",
    "              'min_child_samples':(20,30)\n",
    "             }\n",
    "parameters = {'classifier__' + key: parameters[key] for key in parameters}\n",
    "\n",
    "clf = LabelPowerset(lgb.LGBMClassifier(random_state=7))\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_light = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_light, profiles, target,cv=loo, n_jobs=-1,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted Algorithms\n",
    "#### MLkNN\n",
    "We start with the KNN version for multi-label problems. MLkNN uses k-NearestNeighbors to find nearest examples to a test class and uses Bayesian inference to select assigned labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=7)]: Done 360 out of 360 | elapsed:   47.0s finished\n",
      "C:\\Users\\stef4\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=5 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 5, 's': 0.75}\n",
      "--------------------------------------------\n",
      "Mean: -0.21225910064239828\n",
      "Standard Deviation: 0.3163006707934291\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "parameters = {'k': (2,3,4,5,6,7,8,9,10,13,16,19),\n",
    "              's': (0.5,0.75,1)\n",
    "             }\n",
    "\n",
    "clf = MLkNN()\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_MLKNN = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_MLKNN, profiles, target,cv=loo, n_jobs=6,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BRkNNaClassifier\n",
    "Next up, Binary Relevance multi-label classifier based on k-Nearest Neighbors method. This method assigns the labels that are assigned to at least half of the neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 59 candidates, totalling 1180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  74 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=7)]: Done 674 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=7)]: Done 1180 out of 1180 | elapsed:    9.1s finished\n",
      "C:\\Users\\stef4\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=4 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 4}\n",
      "--------------------------------------------\n",
      "Mean: -0.20248929336188437\n",
      "Standard Deviation: 0.32149968095357107\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "\n",
    "parameters = {'k': range(1,60),\n",
    "             }\n",
    "\n",
    "clf = BRkNNaClassifier()\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_20, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_BRKNN = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_BRKNN, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BRkNNbClassifier\n",
    "\n",
    "Again,Binary Relevance multi-label classifier based on k-Nearest Neighbors method. However, this version assigns the most popular m labels of the neighbors, where m is the average number of labels assigned to the objectâ€™s neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 249 candidates, totalling 4980 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=7)]: Done 590 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=7)]: Done 1590 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=7)]: Done 2990 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=7)]: Done 4790 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=7)]: Done 4980 out of 4980 | elapsed:   47.7s finished\n",
      "C:\\Users\\stef4\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=39 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 39}\n",
      "--------------------------------------------\n",
      "Mean: -0.32354122055674517\n",
      "Standard Deviation: 0.20829391646160197\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import BRkNNbClassifier\n",
    "\n",
    "parameters = {'k': range(1,250),\n",
    "             }\n",
    "\n",
    "clf = BRkNNbClassifier()\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_20, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "best_BRKNN = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_BRKNN, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLARAM\n",
    "Hierarchical ARAM Neural Network for Large-Scale Text Classification\n",
    "\n",
    "This method aims at increasing the classification speed by adding an extra ART layer for clustering learned prototypes into large clusters. In this case the activation of all prototypes can be replaced by the activation of a small fraction of them, leading to a significant reduction of the classification time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=7)]: Done 300 out of 300 | elapsed:   51.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold': 0.04, 'vigilance': 1}\n",
      "--------------------------------------------\n",
      "Mean: -0.2516729122055675\n",
      "Standard Deviation: 0.31688789624164043\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "profiles_ARAM = lil_matrix(profiles).toarray() #transform data with lil_matrix to avoid error\n",
    "\n",
    "parameters = {'vigilance': (0.9,0.95,1,1.05,1.1),\n",
    "              'threshold': (0.02,0.03,0.035,0.04,0.045,0.05),\n",
    "              #'neurons': (),\n",
    "             }\n",
    "\n",
    "clf = MLARAM()\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles_ARAM, target)\n",
    "best_MLARAM = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_MLARAM, profiles_ARAM, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLTSVM\n",
    "Now we will try twin multi-Label Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed: 82.4min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed: 100.5min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed: 121.8min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed: 148.4min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed: 180.4min\n",
      "[Parallel(n_jobs=6)]: Done 3240 out of 3240 | elapsed: 182.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c_k': 9, 'lambda_param': 0.75, 'max_iteration': 400, 'sor_omega': 1.25, 'threshold': 1e-05}\n",
      "--------------------------------------------\n",
      "Mean: -0.19974571734475374\n",
      "Standard Deviation: 0.26953849319251966\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLTSVM\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "profiles_MLTSVM = csr_matrix(profiles) #transform data with csr_matrix to avoid error\n",
    "\n",
    "parameters = {'c_k': (0,3,5,7,9),\n",
    "              'sor_omega': (0.75,1,1.25),\n",
    "              'threshold': (1e-5,1e-6, 1e-7),\n",
    "              'lambda_param': (0.75,1,1.25),\n",
    "              'max_iteration': (400,500,600),\n",
    "             }\n",
    "\n",
    "clf = MLTSVM()\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=6, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles_MLTSVM, target)\n",
    "best_MLTSVM = gs_clf.best_estimator_\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(best_MLTSVM, profiles_MLTSVM, target, cv=loo, n_jobs=6,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers\n",
    "#### Decision Trees\n",
    "We can use decision trees for multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1296 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=7)]: Done 1054 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=7)]: Done 3054 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=7)]: Done 5716 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=7)]: Done 9020 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=7)]: Done 12909 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=7)]: Done 12960 out of 12960 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_impurity_decrease': 0, 'min_samples_leaf': 3, 'splitter': 'best'}\n",
      "--------------------------------------------\n",
      "Mean: -0.07400963597430407\n",
      "Standard Deviation: 0.1537245789059923\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'splitter': ('best', 'random'),\n",
    "              'max_features':('sqrt',None,'log2'),\n",
    "              'class_weight':(None,'balanced'),\n",
    "              'max_depth':(None,20,50),\n",
    "              'min_samples_leaf':(1,3),\n",
    "              'ccp_alpha':(0,0.15, 0.3),\n",
    "              'min_impurity_decrease':(0, 0.15, 0.3)\n",
    "             }\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=7)\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_tree = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_tree, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Approach\n",
    "Now lets try ensemble approaches\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 512 candidates, totalling 5120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed: 44.8min\n",
      "[Parallel(n_jobs=7)]: Done 3249 tasks      | elapsed: 72.3min\n",
      "[Parallel(n_jobs=7)]: Done 4099 tasks      | elapsed: 87.7min\n",
      "[Parallel(n_jobs=7)]: Done 5077 tasks      | elapsed: 111.1min\n",
      "[Parallel(n_jobs=7)]: Done 5120 out of 5120 | elapsed: 119.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': None, 'n_estimators': 100, 'oob_score': True, 'warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.05065578158458244\n",
      "Standard Deviation: 0.12146116828102768\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (100, 150, 175, 200),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'class_weight':('balanced_subsample','balanced',None),\n",
    "              'max_features':('auto','sqrt','log2',None),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced')\n",
    "             }\n",
    "\n",
    "clf = RandomForestClassifier(random_state=7)\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_forest = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_forest, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 768 candidates, totalling 7680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=7)]: Done 4176 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=7)]: Done 5588 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=7)]: Done 7009 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=7)]: Done 7680 out of 7680 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 125, 'oob_score': False, 'warm_start': True}\n",
      "--------------------------------------------\n",
      "Mean: -0.046707708779443254\n",
      "Standard Deviation: 0.11198221889911047\n"
     ]
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini','entropy'),\n",
    "              'n_estimators': (50,75,100,125),\n",
    "              'bootstrap':(True,False),\n",
    "              'oob_score':(True,False),\n",
    "              'max_features':('sqrt',None,'log2'),\n",
    "              'warm_start':(True,False),\n",
    "              'class_weight':(None,'balanced'),\n",
    "              'max_depth':(None,10)\n",
    "             }\n",
    "\n",
    "clf = ExtraTreesClassifier(random_state=7)\n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=7, cv=fold_10, \n",
    "                      scoring=make_scorer(hamming_loss, greater_is_better=False), verbose=1)\n",
    "\n",
    "gs_clf.fit(profiles, target)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "\n",
    "best_extra = gs_clf.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_extra, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print('--------------------------------------------')\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `gp_minimize` to find the optimal number of n_estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features =profiles.shape[1] #number of columns\n",
    "extra_trees = ExtraTreesClassifier(random_state=7, bootstrap=False,class_weight= None,\n",
    "                                                  max_depth=None, max_features=None, oob_score=False,\n",
    "                                                  warm_start=True, criterion='entropy')\n",
    "\n",
    "# The list of hyper-parameters we want to optimize\n",
    "space  = [Integer(90, 170, name='n_estimators'),\n",
    "         ]\n",
    "\n",
    "# this decorator allows your objective function to receive a the parameters as\n",
    "# keyword arguments. This is particularly convenient when you want to set\n",
    "# scikit-learn estimator parameters\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    extra_trees.set_params(**params)\n",
    "    \n",
    "    return np.mean(cross_val_score(extra_trees, profiles, target, cv=fold_50, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 56.4638\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 58.2788\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 34.7433\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 55.2621\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 35.4731\n",
      "Function value obtained: -0.0474\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 39.6224\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 39.3817\n",
      "Function value obtained: -0.0479\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 46.6255\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 53.7811\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 51.7997\n",
      "Function value obtained: -0.0482\n",
      "Current minimum: -0.0485\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 29.7964\n",
      "Function value obtained: -0.0487\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.8980\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 32.2512\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.6280\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.5038\n",
      "Function value obtained: -0.0473\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.2539\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.5462\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 46.1333\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.8896\n",
      "Function value obtained: -0.0486\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 34.3408\n",
      "Function value obtained: -0.0479\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 43.8416\n",
      "Function value obtained: -0.0479\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.6572\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 29.4740\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 30.7679\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.6996\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 55.0763\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.3872\n",
      "Function value obtained: -0.0480\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.9832\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 46.7359\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.1451\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 35.1660\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 43.2353\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.5687\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.7468\n",
      "Function value obtained: -0.0484\n",
      "Current minimum: -0.0487\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.7260\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.3539\n",
      "Function value obtained: -0.0473\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.5026\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 45.2729\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.8408\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.1070\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.2991\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 40.6985\n",
      "Function value obtained: -0.0479\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 45.2454\n",
      "Function value obtained: -0.0478\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.9866\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 48.9406\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.1167\n",
      "Function value obtained: -0.0474\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.5047\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.0686\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.0306\n",
      "Function value obtained: -0.0482\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.2961\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 41.8312\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.3622\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.5473\n",
      "Function value obtained: -0.0474\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.9437\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 55.0140\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.8117\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.5343\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.2614\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.9116\n",
      "Function value obtained: -0.0479\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 37.1464\n",
      "Function value obtained: -0.0474\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.4047\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.7195\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 40.5066\n",
      "Function value obtained: -0.0475\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.4278\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.1198\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.6484\n",
      "Function value obtained: -0.0475\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.0588\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.2304\n",
      "Function value obtained: -0.0476\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.3265\n",
      "Function value obtained: -0.0485\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.5086\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.9031\n",
      "Function value obtained: -0.0483\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n",
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 36.8378\n",
      "Function value obtained: -0.0473\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.7170\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n",
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 34.0982\n",
      "Function value obtained: -0.0477\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 55.2781\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 76 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 76 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.5247\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 77 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 77 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.7312\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 78 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 78 ended. Search finished for the next optimal point.\n",
      "Time taken: 40.7840\n",
      "Function value obtained: -0.0481\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 79 started. Searching for the next optimal point.\n",
      "Iteration No: 79 ended. Search finished for the next optimal point.\n",
      "Time taken: 33.6226\n",
      "Function value obtained: -0.0482\n",
      "Current minimum: -0.0488\n",
      "Iteration No: 80 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stef4\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 80 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.9197\n",
      "Function value obtained: -0.0488\n",
      "Current minimum: -0.0488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Best score=-0.0488'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp = gp_minimize(objective, space, n_calls=80, random_state=1, verbose=True)\n",
    "\n",
    "\"Best score=%.4f\" % res_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number was calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[167]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_gp.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the LOO hamming loss for the optimal number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.04730995717344754\n",
      "Standard Deviation: 0.11197216175425515\n"
     ]
    }
   ],
   "source": [
    "extra_trees = ExtraTreesClassifier(random_state=7, bootstrap=False,class_weight= None,\n",
    "                                                  max_depth=None, max_features=None, oob_score=False,\n",
    "                                                  warm_start=True, criterion='entropy', n_estimators=125)\n",
    "\n",
    "scores = cross_val_score(extra_trees, profiles, target,cv=loo, n_jobs=7,\n",
    "                         scoring=make_scorer(hamming_loss, greater_is_better=False))\n",
    "print_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately the optimal number of `n_estimators` based on gp_minimize did not produce a lower hamming loss than before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEURAL NETWORK\n",
    "Now we will try to use a neural netwrok to predict the multiple labels. Neural networks can be used for multi-label problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using standard scaler in order to scale down the values (necessary step for neural network):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scripts defines the neural network and uses cross validation to calculate the hamming losses. The script is based on the following [article](https://machinelearningmastery.com/multi-label-classification-with-deep-learning/). In detail: \n",
    "* The sigmoid function is used in the output layer as we only want the brand label to get values of 0 or 1. The neural network uses probabilitites for the output labels. That's why the function `round()` is used to transform the probabilities into 0 and 1\n",
    "* Number of nodes in the output layer matches the number of labels.\n",
    "* Binary cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model description\n",
    "def get_model(n_inputs, n_outputs, number_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(number_neurons, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tfa.metrics.HammingLoss(mode='multilabel')])\n",
    "    return model\n",
    " \n",
    "# evaluate a model using 20-fold cross-validation\n",
    "def evaluate_model(X, y, number_neurons, number_epochs, number_batch, fold_split):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    # define evaluation procedure\n",
    "    cv = fold_split\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs, number_neurons)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=number_epochs, batch_size=number_batch,\n",
    "                  workers=7, use_multiprocessing=True)\n",
    "        # make a prediction on the test set\n",
    "        yhat = model.predict(X_test)\n",
    "        # round probabilities to class labels\n",
    "        yhat = yhat.round()\n",
    "        # calculate hamming loss\n",
    "        acc = hamming_loss(y_test, yhat)\n",
    "        results.append(acc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different combinations of number of neurons, epochs and batch sizes with a 20-fold validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000254E2CFDAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000254E724E040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Hamming loss: 0.067 (0.020)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 150, 150, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.066 (0.016)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 100, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.063 (0.015)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 150, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.065 (0.015)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 200, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.066 (0.016)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 200, 20, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.065 (0.015)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 180, 5, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.064 (0.017)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 300, 100, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.062 (0.016)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 300, 150, 10, fold_20)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the best ones for loo cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.062 (0.130)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 225, 200, 10, loo)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.065 (0.135)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 180, 200, 10, loo)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss: 0.062 (0.131)\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 300, 100, 10, loo)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_model(scaler.transform(profiles), target, 300, 150, 10, loo)\n",
    "print('Hamming loss: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Now let's check all the hamming losses for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "hamming_loss = {'Binary Relevance-Decision trees': 0.07501338329764454,\n",
    "              'Binary Relevance-Random forest': 0.05259635974304069,\n",
    "              'Binary Relevance-Extra trees': 0.04730995717344754,\n",
    "              'Binary Relevance-LightGBM': 0.0485144539614561,\n",
    "              'Binary Relevance-XGBoost': 0.05072269807280514,\n",
    "              'Binary Relevance-Logistic regression': 0.06684957173447538,\n",
    "\n",
    "              'Classifier Chains-Decision trees': 0.07508029978586724,\n",
    "              'Classifier Chains-Logistic regression': 0.06510974304068523,\n",
    "              'Classifier Chains-Random forest': 0.05815042826552463,\n",
    "              'Classifier Chains-Extra trees': 0.05293094218415417,\n",
    "              'Classifier Chains-LightGBM': 0.04898286937901499,\n",
    "              'Classifier Chains-XGBoost': 0.05580835117773019,\n",
    "\n",
    "              'Label Powerset-Extra trees': 0.056076017130620985,\n",
    "              'Label Powerset-Random Forest': 0.05968950749464668,\n",
    "              'Label Powerset-LightGBM': 0.06336991434689508,\n",
    "\n",
    "              'MLkNN': 0.21225910064239828,\n",
    "              'BRkNNaClassifier': 0.20248929336188437,\n",
    "              'BRkNNbClassifier': 0.32354122055674517,\n",
    "              'MLARAM': 0.2516729122055675,\n",
    "              'MLTSVM': 0.19974571734475374,\n",
    "              \n",
    "              'Decision trees classifier': 0.07400963597430407,\n",
    "              'Random Forest': 0.05065578158458244,\n",
    "              'Extra Trees': 0.046707708779443254,\n",
    "\n",
    "              'Neural Network': 0.062,\n",
    "\n",
    "\n",
    "              'Dummy classifier': 0.22330032119914348\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "hamming_loss = dict( sorted(hamming_loss.items(), key=operator.itemgetter(1),reverse=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJQAAAJnCAYAAADBfAnIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAACtsklEQVR4nOzdebxVVfnH8c9XHEBBKDVTTHHAHBBuCJpjOFumaalUpmIqamppP0xLUyzLgSZnU1K0TElxSk0wFSVQmUenUiynnMMJJ3h+f6x1dHs4595z4MLlXr7v1+u+7j5rr73Ws/c5+Oo+PWsdRQRmZmZmZmZmZma1Wq6lAzAzMzMzMzMzs9bFCSUzMzMzMzMzM6uLE0pmZmZmZmZmZlYXJ5TMzMzMzMzMzKwuTiiZmZmZmZmZmVldnFAyMzMzMzMzM7O6OKFkZmZm1sIkdZMUkoa1dCwtRdJoSdHScRRJGpDflwEtHYstfpIG5/e73yKOMyyP061ZAjMzW0o5oWRmZmZ1kXRq/mMpJH2+peMxMzMzsyXPCSUzMzOrmSQBRwClSpIjWzAca1sOATZt6SDMzMysNk4omZmZWT12B7oBVwP/BQ6VtGKLRmRtQkT8JyIea+k4zMzMrDZOKJmZmVk9ShVJVwDXAqsD+xU7SLorL4frVWkASf3z+V+VtX9a0tmSHpU0V9IcSfdI2r3CGB/tbSNpz7z/zpziHjyS9pX0J0lPSHo7/0yS9H1JFf83kKSNJY2Q9HruP07SXo3tpSNpHUkXSXpK0nuSXpV0m6S+TTzLivJ+StdLekXSu5ImSvpqhX6dJZ0k6V5Jz0p6X9LLee5tqowd+VmtKelKSS8W7nOH3GcVSUMk/TvfzyxJB1QYq/ge7CZpjKS3cgxXSeqS+31B0u35mb6V4+tWYbwF9lCS1C/PMVhSg6Q7JP1P0juS7pe0bZX7XCvH8FL+LE2VdGhxvBreikZJ2jJ/Vl7Kz+nfki6RtFaFvmtK+pWkx/Pz/l8+HiZpg0I/5TjH5ef4rqRnJI2U1L/GuD7aByiPNSU/g5fye/7ZKtc167+/RuIr7S+0vqTjJD2S7/NpST+RpNzvAEnj8/N6SenfWIcqY+6i9N+d1/J78YSkcyR1rtJ/y9z/TUlvSPq7qvybKVyzSY79GaV/ay9K+rO87NfMlmHLt3QAZmZm1jpIWhPYB3giIsZJegP4P2AgMLzQ9WpgD9ISpv+rMNSh+fewwtjrAaNJ1U9jgLuAVYCvAndJOioirqgw1v7AnsDfgMuA9QrnzgHmAw8DzwGdgZ2B84G+wMFl97cJMA74FHAHMB3YALgZuLPKM+kNjAI+DYwEbiIl2fYF/iFpv4ioeG0V6wHjgaeAP+Zx+wO3Sto1Iu4r9N0U+AXwQI73dWBd0nv0ZUl7R8RdFeboAowF3gSuy3N8ExiZ/6j+fW67HVgB+BYwXNIzEfFQhfH2Ib1Pt5Peg22BAUA3ST8G7iG9p38AtgD2BjaQ1DMi5tf4XPoAPwIeBIbm+/wGcI+khoh4vNRR0mdyv/XysxkHfBa4hPReLTKlBN8IQMCNwL+BLYFjgK9J2j4iZue+K5Oe94bA3cBf83XrAV/L1z+Vh/4F8GNgNvAXYA6wFunzegCf/HfWlBNJFYXDSf+etgcOA/pJ2joiXi7cz+L499eUXwH9SM9jFOlz9AtgRUmvkf793pLj2Q04FmhHesYfkXQUcCnwNnAD8FIe92Rgb0nbRcT/Cv23Bf4OrEj69/ovoCHf/72VApW0Z+67Qo73X8A6wNeBvSTtFBGT67h3M7O2ISL84x//+Mc//vGPf5r8AU4h7Z3040LbRFLSZqNCW3vgf6QlccuXjfFZ4ENgUln76DzON8vauwBTgbnAmoX2ATmW+cCeVeLdsELbcqSEVwBbl527J7cfU9b+5dwewIBC+/KkPyzfBb5Uds3apCTWC8BKNTzbboU5zig7t0duv7OsvTOweoWx1gGeBx6tcK40x2XAcoX2g3P7a6Q/mNsXzu2Qz91cNlbpPfiweP/5Gd9dGO+gsuv+kM99rcJnIMra+lV69vncUbn9kirjn1vW3gt4L58bXONnfkD53EBH4FVgHrBDWf+Tc/9Rhba9c9tvK4y/ItCp8PpV4Flg5Qp9F3ivq8Q8OM/3PvCFsnO/zef+sLj//TUS37B87dNA17K5XiElhl4GNi2cWwl4JL9/nym0r5fb3gA2KZvnkjzP5YU2AY9V+fz9oPBZ61do/xQpWfsKsFnZNT2At4DJVe6xWz3Pxj/+8Y9/WtuPl7yZmZlZk/IylCNIf0BeUzg1jPRH2kebc0fEu6TqijVJyZCi75CqDK4ujN0L+BIwIiKuL3aOVFlwBilJ9Y0Kod0alatwiIgnK7TNJ1UoUYxN0udI1Uv/IlXoFK/5G6miodxepKqTCyPi/rJrngfOIyXQdqkUXxX/Bs4qG2sk8B9gq7L2ORHxSvkAEfEsqeplE0nrVpjjHeCk+GR10J9JiaFPAT/I72FpvDGkP/4bqsR8XfH+87h/zC9nRsS1Zf1Ln59q41UyNiKGlbVdmWP+6Lko7ef1LVJlT/lznMYnP7sL62ukCq7h+dkU/Zr0rHar8Oznlg8UEe9HxJtlzR+QklXlfRd4r5vwx4iYUtY2mPRsvi1pJVh8//5q8POIeK5srtuAlYFLI+LRwrn3SJVWK/LJjdu/k9suigX33zqVVIV3cOleSdVznwceiIhby/pfBCzw3wxSpWUXUqL3keKJiJhJWv77BUmbNXXDZmZtjZe8mZmZWS12JiVPRhb/CCQlIn4NDJB0WkR8kNuHkZJMh5KWY5UcSvqD+c+FttLeJZ1VeW+bNfLvSt8ANr5awJJWA04CvkJaurZKWZeuheOG/PvBqLwM6x/ArmVtpbjXqxJ39/x7U6osmatgakQskEwAninM9xFJ25EqK7YBPkP647qoKykZVfREeRIjIuZJehFYJSKeYkHPAVtXiXlihbbn8+9JVcaCVElVqwXmiIgPcsyfKjR/HugATKyQqIH0Ph5Rx7yV9M6/F1geFREfSnqAVHH2BdKzv590z6fkJZJ3kpbAVXqvrwWOBx6R9Jd87YMRMWch4ry/vCEi5kiaSkogbUqqPlos//5q0Byfm8bei9clTQF2BDYBphX6V3o28yT9g/TfuaLS8+lV5flsnH9vSqqiMjNbZjihZGZmZrUYmH8PKzZGxGuS/kqqXijtB0OkPZaeAPaR9Kn8x11v0hKRW8qqLVbLv3fLP9V0rND230odlTaEngCsT/qj9xrS8qsPSdUGPyAtoykpbd77YpW5K7WX4l5gw+oyleKu5n9V2j+k7MtUJO1Het7vkpaYPUlaLjSftFTsS3zyHkuqJSc+bOJctf/dWOmaD2s4t0KV8Sr5X5X2D0kVbyUL8z7WqzTHC1XOl9q7AETEG5K+CJxJ2ieoVBn3iqRLgLMKidgTSfspHUZaYnoK8KGkO4H/i4h/1RFntXst/Zsp3Uez//urUXN8bup6L2j681HpfkrP58gK54rq+XduZtYmOKFkZmZmjZK0BmmTaYDrJF1XpetAckIpu4a07Kg/ac+e0mbcV5ddV/rj8QcRcUGd4UWV9iNIyaQzI2Jw8UTeePoHZf3fyL/XrDJepfZS3F+LiNuaDrXZ/Zy0T06f4vIgAEm/JyWUljUL8z7Wq/S+V/y2NNIm2sV+pWWIh+elo5uRKv6OBU4nJQp/mvvNA34H/C5vLr49acP0A4DNJW2el3/Votq9luKeU/a7Of/9LSnF92JWhfPl70Xpd1PPptIcvSJiet0Rmpm1Yd5DyczMzJpyKGkp1STShseVfl4GdpW0fuG6a0jVModKKn1b2Ct8cgkcQOmbw3Zoxpg3yr9HVDhXKdEyNf/eRlKl/320fYW2xRF3PTYCHqmQTFqOyvEuCx4j7VXUU1KnCueb47mU9iXqV35C0vJ8/HlY4Fu/IpkVERfycTXQvpUmiYiXIuKmiDiQtKRrQ1KFX60W+JxL6kxa3vkuUPrctPTneFE09l50YcF7Lb0nlZ5NO5bOf+dmZkstJ5TMzMysKaWlHt+LiCMq/ZA2si5t3A1ARDxD+kP4i6SKoDWAPxeW95T6TSR9NfjXJX23UgCStsgVG7V6Ov/uVzbOF0hfy/4JEfEf0jddbUT69rDiNXuy4P5JALeSlpkdK+krVeLeJn9t/OLwNNBd0tqF+UTaeHmZ3CA4It4nbd7cGTiteC5vPn1IM0xzC2n55LfyUraiE0iVcX/PnykkbS6pUkVMqe2d3G+lvCfWJ+Rk7KeLfWt0cP68Fw0mPZvrSpVOi+nf35LyJ9KebMdL2qjs3M+BVYE/Faq6xgGPAztK+lpZ/+NYcP8kgKtISy7PkLRV+UlJy0nqt7A3YGbWmnnJm5mZmVWV/1DaGJgREY1twPsH0rcqHSbpjIgo7XdyNSkZ88vC60q+TUo+/UHS94GHSX/ErQP0JFVmbAO8VGPo15A25P6dpJ2Af5I2yf4qcBNpGV65Y0mbJV+SE0TTSZt5f4OUPPoaqeIK+GhT6K8DI4E7JI0jVTq9A3wO6JuvX4v6EgG1+i1pKeEUSSNIf1hvR0om/ZX0dfXLolNIS8p+JGlrUhJhLeBA0obY+1J4H+sVEW/lxMsNwP2SbiBtvr0lsDtpH55iUnI3YIikB4EnSJ/hdfj48zQk9+sA/EPSv0jVgP8mfbvabqQNn28rr0Zrwt+AsXlz7xdI1TfbkxKRp5T1be5/f0tERDwt6QTgYmByvteXSRVI25Aq1k4u9A9Jh5P2HBsh6SbSNzs2kL6N8S5gz7I5XpW0P3Az8JCke0jL64L073wb0j5L7RffnZqZLZ1coWRmZmaNKVUnDW2sU0Q8Dfyd9Id7MZFxE2lfmxVIXyG/wDKgfP2zpD/ITyV9ZfpBwPdJX/P9H9If6DNqDToinictUbmD9Ef0ccB6wPdY8I/p0jWPkP44vDlfewLp27r2I307GHy8R0/pmulAL+BcUuXHYcAx+V6mAAeTlvk1u4j4fZ7vBdKyxINI3wa3NRWWWy0rIuJF0ufmGmBz0kbXXyC999fmbm9UvrrmOW4lJe/uJG2yPYiU9LkM2LLsm/JGAhcCK5OSSP9H+uaxu4EdIqK079jbpOTHv3L8PyAlet4gfaaa2vy93G9J99xA+ixvQtpUf9uI+ERiqLn//S1JEXEJ6T14iJT8/SHpGw+HANtExGtl/ceS/n3/Hfgy6Vv1ViRVMz5cZY57SIm1S0j/TTgaOJyUaLuXtM+VmdkyRxEtvZeemZmZ2dJN0rWkP+43iYjHWzoeWziSfgH8BNgzIka2dDyLQ/5q+zOAnSJidMtGY2ZmbZkrlMzMzMz4aC+UBb7lSdIupCVyjziZ1DoU95UqtG1Bqrp5Dbh/iQdlZmbWxngPJTMzM7NkReAZSfeR9l75kLRkajfgfdIeS9Y6TMx7Ec0kLSXrDuxF+j9Tj4qId1syODMzs7bACSUzMzOz5APSHjg7k/YhWpm0/9ENwDkRMaWRa23p8nvS5tvfAjqRNpgeCfzKy8DMzMyah/dQMjMzMzMzMzOzungPJTMzMzMzMzMzq4uXvJktZl26dIn1N9yopcOwVmLu22/TYZVVWjqMpYqfSWV+LlYPf16sHv68WK38WbF6+PPSek2dPOmViFijvN0JJbPFbM0112T0uIktHYa1EhPHjabPtv1aOoylip9JZX4uVg9/Xqwe/rxYrfxZsXr489J6dWmvf1dqd0LJbDF7ds777HzaNS0dhrWwe886pKVDMDMzMzMzazbeQ8nMzMzMzMzMzOrihJKZmZmZmZmZmdXFCSUzMzMzMzMzM6uLE0pmZmZmZmZmZlYXJ5RsiZI0T9LUws8pTfT/ySLOd3Ge5xFJcwvz7r8o45qZmZmZmZkty/wtb7akzY2Ihjr6/wT4ZXmjJAGKiPmNXRwRx+b+3YDby+eWtHxEfFhHPGZmZmZmZmbLPFcoWYuT1FnS45I+n19fJ+lISecAHXJF0bWSuuV+1wAzgc9JulTSREmzJJ1Z43z9JI2RdBvwiKR2koZImiBpuqSjCn1PKrSfmdtWkXSHpGmSZkrq3/xPxczMzMzMzGzp5QolW9I6SJpaeH12RAyXdBwwTNL5wKci4goASceVqopylVF34NCIeCi3nRoRr0lqB9wjqWdETK8hjt5Aj4iYLWkgMCci+kpaCRgraVSeqzuwFSDgNkk7AmsAz0fEXjmGzov2SMzMzMzMzMxaFyeUbEmruOQtIu6WdABwMdCrkev/XUomZQfmhNDywFrAZkAtCaXxETE7H+8O9Czsq9SZlEjaPf9Mye0dc/sY4NeSziUtoxtTPniOaSDAymt2qyEcMzMzMzMzs9bDCSVbKkhaDtgUeAf4FPBsla5vF65ZHxgE9I2I1yUNA9rXOOXbhWMBx0fEyLKY9iBVUP2+Qry9ga8AZ0m6JyJ+VjwfEZcDlwOs8tn1o8aYzMzMzMzMzFoF76FkS4sTgUeBbwNXSVoht39QOC63KikxNEfSmsCXF3LukcAxpXkkbSxpldz+XUkdc3tXSZ+RtDbwTkT8CRhCWj5nZmZmZmZmtsxwhZItaeV7KN0FXAUcAWwVEW9KegA4DTiDVOUzXdJk4NTiQBExTdIU4DHgGWDsQsY0FOgGTM7fHvcysG9EjJK0KfBgauYt4DvARsAQSfOBD4BjFnJeMzMzMzMzs1bJCSVboiKiXZVTmxb6/LBwfDJwcqFfj7LxBtQ479OlayNiNDC6cG4+8JP8U37d+cD5Zc1PkqqXzMzMzMzMzJZJXvJmZmZmZmZmZmZ1cULJzMzMzMzMzMzq4oSSmZmZmZmZmZnVxQklMzMzMzMzMzOrizflNlvM1um8IveedUhLh2FmZmZmZmbWbFyhZGZmZmZmZmZmdXFCyczMzMzMzMzM6uKEkpmZmZmZmZmZ1cV7KJktZiu99R/mnLtFS4dhS4nOJ89o6RDMzMzMzMwWmSuUzMzMzMzMzMysLk4omZmZmZmZmZlZXZxQMjMzMzMzMzOzujihZGZmZmZmZmZmdXFCKZM0T9JUSdMkTZa0bW5fW9KNSziWYZJmF+LZpYn+3STNXFLxLQpJgyU9l++t9NOlkf79Su/FIszZTdK3F2UMMzMzMzMzM/uYE0ofmxsRDRHRC/gxcDZARDwfEfs3xwSS2tXR/aSIaABOAC5rjvmXIr/Nz7r0879G+vYDKiaUJNX6LYXdgIoJpTrGMDMzMzMzM7PMCaXKVgVeh09W/0gaIOkmSXdJ+qek80oXSLpU0kRJsySdWWh/WtK5kiYDp+TfpXPdi6+reBDomvu3kzRE0gRJ0yUdVd65Wh9J10vaq9BvmKT98/2NyVVZxcqsfpJGS7pR0mOSrpWkfK6vpHG5emq8pE61xNYYSSdKujIfbyFppqTNgKOBE3Ml0w457sskPQycJ2krSQ9KmpJj+nyF4c8BdshjnJjfx9sk3QvcI2kVSVfme5ki6WtNPMu1JD2Qx5spaYd67tXMzMzMzMystXN1xsc6SJoKtAfWAnau0q8B+ALwHvC4pAsj4hng1Ih4LVch3SOpZ0RMz9e8GhG9ASTtKqkhIqYChwFXNRHXnsAt+fhwYE5E9JW0EjBW0iggCv2r9RkOHAjcIWlFYBfgGEDAbhHxrqTuwHVAnzzWF4DNgeeBscB2ksbnsfpHxARJqwJzq80bEbMr3NOJkr6Tj1+PiJ2A84HRkvYDTgWOiohHJF0GvBURv8rP73BgHWDbiJiX598hIj6UtCvwS+AbZfOdAgyKiK/mMQYAvYGe+T37JXBvRHw3L78bL+nvwEFVnuXXgZER8Yv8fq9c5b0zMzMzMzMza5OcUPrY3LzEDEnbANdI6lGh3z0RMSf3ewRYD3gGOFDSQNIzXQvYDCgllIYXrh8KHCbph0B/YKsq8QzJiY51gG1y2+5AT0mlJXidge7AE4XrqvX5G3B+TozsCTwQEXMldQYuktQAzAM2Low1PiKezfc6lbR0bA7wQkRMAIiIN/L5avNWSij9tpQgKomI+TnRMx34fUSMrfJcAG6IiHmFea7OybAAVmjkuqK7I+K1fLw7sI+kQfl1e2Bdqj/LCcCVklYAbsnJwU/In4WBAFus3b7GkMzMzMzMzMxaByeUKoiIByWtDqxR4fR7heN5wPKS1gcGAX0j4nVJw0hJiZK3C8cjgDOAe4FJEfFqlTBOiogbJR0PXAlsSaomOj4iRhY7SupWfFmpT+43GtiDlMi6PjefCLwI9CItgXy3sXutEmvVeSX9AtgLoJSwa0R34C1g7Sb6FZ/nz4H7ImK//BxGN3FtpTEEfCMiHi92yEv8qj3LHUn3NUzSbyLimuL5iLgcuBygZ9cOUX69mZmZmZmZWWvmPZQqkLQJ0A6oluwptyopQTFH0prAl6t1jIh3gZHApTS93A3gImA5SXvk647JlTFI2ljSKmX9G+sznLTMbgfgrtzWmVRxNB84mHTfjXkcWEtS3zx+J6WNrSvOGxGnljbfbmzQXCl1AbAjsFqhKuhNoFMjl3YGnsvHA6r0aWqMkcDxOYGEpC8U2he4J0nrAS9GxBWkirPejd2bmZmZmZmZWVvjCqWPlfZQglSxcmjeo6fJCyNimqQpwGOk5W+NLdcCuBbYDxhVw9gh6SzgR8BupGVnk3Py42Vg37JLhjbSZxTwR+DWiHg/t10CjJB0CCnJ9DaNiIj3JfUHLpTUgbR/0q5NzFuuuIcSud/pwMUR8UTeJ+k+SQ8AfwVuzBtlH19hrPNIS95OA+6oMt90YJ6kacAw8obrBT8HfgdMl7QcaZneVxu5p37ASZI+IFVUHVJlXjMzMzMzM7M2SRFejbOk5b16OkfET1s6Flv8enbtELcftVFLh2FLic4nz2j0/MRxo+mzbb8lE0wr4WdSmZ+L1cOfF6uHPy9WK39WrB7+vLReXdprUkT0KW93hdISJulmYEOqf4ucmZmZmZmZmdlSzQmlJSwi9mvpGMzMzMzMzMzMFoU35TYzMzMzMzMzs7o4oWRmZmZmZmZmZnXxkjezxey9jus2uRGzmZmZmZmZWWviCiUzMzMzMzMzM6uLE0pmZmZmZmZmZlYXJ5TMzMzMzMzMzKwu3kPJbDF7bu5zfOXy7Vo6DFtK3TlwbEuHYGZmZmZmVjdXKJmZmZmZmZmZWV2cUDIzMzMzMzMzs7o4oWRmZmZmZmZmZnVxQsnMzMzMzMzMzOrihFITJM2TNFXSNEmTJW2b29eWdOMSjmWYpNmFeHZpon83STOXVHyLQtJgSYMqtI+r4dqnJa1eob1f6f0qtH1H0nRJs/IzHCqpSz43WtLj+fk+Kmlg2Rxjysaa2lqer5mZmZmZmVlzckKpaXMjoiEiegE/Bs4GiIjnI2L/5phAUrs6up8UEQ3ACcBlzTH/0iwitm26V1X9gI+ul7QncCLw5YjYHOgNjAPWLFxzUH6+2wHnSlqxcK6TpM/lsTZdhLjMzMzMzMzMWjUnlOqzKvA6fLL6R9IASTdJukvSPyWdV7pA0qWSJuaKmDML7U9LOlfSZOCU/Lt0rnvxdRUPAl1z/3aShkiakKtvjirvXK2PpOsl7VXoN0zS/vn+xuSqrGJlVr9cyXOjpMckXStJ+VxfSeNy5c94SZ1qia0xkt7Kv5eTdEme825Jd0oqJvSOz3HOkLSJpG7A0cCJuZJoB+BUYFBEPAcQEfMi4sqIeLzC1B2Bt4F5hba/AP3z8beA6+q5FzMzMzMzM7O2YvmWDqAV6CBpKtAeWAvYuUq/BuALwHvA45IujIhngFMj4rVchXSPpJ4RMT1f82pE9AaQtKukhoiYChwGXNVEXHsCt+Tjw4E5EdFX0krAWEmjgCj0r9ZnOHAgcEeuxtkFOAYQsFtEvCupOyl50ieP9QVgc+B5YCywnaTxeaz+ETFB0qrA3GrzRsTsJu6v3NeBbsBmwGeAR4ErC+dfiYjekr5HShodIeky4K2I+BWApM2BphJ110p6D+gOnBARxYTSCNL78itgb+Ag4OA678PMzMzMzMys1XOFUtNKS942ISVxrilV5JS5JyLmRMS7wCPAern9wFxtNIWUhNmscM3wwvFQ4LCceOoP/LlKPEMkPZHPn5vbdgcOyYmvh4HVSAmRomp9/gbslJM9XwYeiIi5wArAFZJmADeUxT0+Ip6NiPnAVFKi5/PACxExASAi3oiID2uMrRbbAzdExPyI+C9wX9n5m/LvSTmeRknaIlcuPSmpf+HUQRHRE1gXGCRpvcK5V4HXJX2TlNB6p5HxB+bKtIlN3pmZmZmZmZlZK+MKpTpExINKmz+vUeH0e4XjecDyktYHBgF9I+J1ScNIlU4lbxeORwBnAPcCkyLi1SphnBQRN0o6nlShsyWpmuj4iBhZ7JiXfX30slKf3G80sAcpkXV9bj4ReBHoRUo8vtvYvVaJteq8kn4B7AWQ9yxaVKWYGotnFmnfpPsiYgbQIOkioEN5x4h4OScCtwb+XTg1HLgYGNBYMBFxOXA5QMd1O0Zjfc3MzMzMzMxaG1co1UHSJkA7UqVKLVYlJY3mSFqTVAFUUa5sGglcStPL3QAuApaTtEe+7hhJK+Q4N5a0Sln/xvoMJy2z2wG4K7d1JlUczSct62pq4/DHgbUk9c3jd5K0fLV5I+LUXPnVUMO9Qlpa9428l9KapA23m/Im0Knw+mzgV5LWKbQtkEzKca5MWtr3ZNmpm4HzSPdlZmZmZmZmtkxyhVLTSnsoQaq2OTQi5lVe9fZJETFN0hTgMeAZUlKkMdcC+wGjahg7JJ0F/AjYjbTMa3JejvcysG/ZJUMb6TMK+CNwa0S8n9suAUZIOoSUZHqbRkTE+3np2IWSOpD2T9q1iXnLnSbphMKYxcTPCNL+To+QnuVkYE5jMQF/BW6U9DVSldSdktYA/paXFv4PmMknk0PXSpoLrAQMi4hJZff5JnmpYS2fATMzMzMzM7O2yAmlJkRExcqciHga6JGPhwHDCue+WjgeUOX6bhWatweuKtsIunjNgLLXI0iJFoCf5J+iOYUY51fpQ0R8AHy6rO2fQM9C08m5fTQwutDvuMLxBOCLFUKvOG/ZfIOBwRXaO5bilzQoIt6StBowHpiRz3Ur9J9Irl6KiCfK7oGIuBq4ukoM/RqJr1uFtqfJz9fMzMzMzMxsWeKE0lJC0s3AhlT/FjmD2yV1AVYEfp435zYzMzMzMzOzJcwJpaVEROzX0jEs7RqrIDIzMzMzMzOzJcebcpuZmZmZmZmZWV1coWS2mHXt0JU7Bza1H7uZmZmZmZlZ6+EKJTMzMzMzMzMzq4sTSmZmZmZmZmZmVhcnlMzMzMzMzMzMrC5OKJmZmZmZmZmZWV28KbfZ4vb880zd7UstHYUtxRruvr+lQzAzMzMzM6uLK5TMzMzMzMzMzKwuTiiZmZmZmZmZmVldnFAyMzMzMzMzM7O6OKFUJ0mflXS9pCclTZJ0p6SNJXWTNLMZ5/mZpF3z8Q6SZkmaKqmrpBsXceyOkn5fuIfRkrZemHuQdLSkQxYlnjzOAEkXVWi/U1KXJq4dLalPhfYGSV8pa9tT0nhJj+XnOVzSuvncMEmzc/tjks4om+M/klRou0XSWwtxu2ZmZmZmZmatmjflrkNOJtwMXB0R38xtvYA1gWeac66IOL3w8iDg7Ij4U369f63jSFo+Ij4sax4KzAa6R8R8SesDmwEvLkScl9V7TZ3jf6XpXlU1AH2AOwEk9QAuBPaJiEdz2z5AN+A/+ZqTIuJGSe2BRyRdExGz87n/AdsB/8hJrrUWITYzMzMzMzOzVssVSvXZCfigmESJiGkRMabYKVf6jJE0Of9sm9vXkvRAroCZmSuP2uXKmJmSZkg6MfcdJml/SUcABwI/l3RtsYooXztE0gRJ0yUdldv75flvAx4pi21DYGvgtIiYn+9hdkTckbu0k3RFrogaJalDvu7IPM80SSMkrZzbB0salI9HSzo3VwA9IWmH3L55bpua4+xe6wOX9LSk1fPxTyU9Lukfkq4rzZsdUJxX0orAz4D+ed7+wMnAL0vJpHzvt0XEAxWmbp9/v11oux74Zj7+OnBTrfdhZmZmZmZm1pY4oVSfHsCkGvq9BOwWEb2B/sAFuf3bwMiIaAB6AVNJVTRdI6JHRGwBXFUcKCKGAreRKmcOKpvncGBORPQF+gJH5mojgN7ADyJi47JrNgemRsS8KrF3By6OiM1JFTnfyO03RUTfiOgFPJrnrmT5iNgKOAEoLRk7Gjg/33cf4Nkq11YlqW+OpRfw5TxO1Xkj4n3gdGB4RDRExHDSvU9uYqohkqbmGK+PiJcK5+4BdpTUjpRYGl7vfZiZmZmZmZm1BU4oLR4rAFdImgHcQFpOBjABOEzSYGCLiHgTeArYQNKFkvYE3qhjnt2BQ3IC5GFgNVJCCGB8YalWPWZHxNR8PIm0HAygR656mkFagrd5letLVTvFax8EfiLpZGC9iJi7EHFtB9waEe/m5/bXGuatStJquXLpibJKp5Ny4uuzwC6l6rJsHvAPUjKpQ0Q83cj4AyVNlDSxqVjMzMzMzMzMWhsnlOozC9iyhn4nkvYj6kWqpFkRIC+t2hF4Dhgm6ZCIeD33G02q5BlaRzwCjs8VOA0RsX5EjMrn3q5yzSygV66yqeS9wvE8Pt5naxhwXK6iOpOPl4RVu/6jayPiz8A+wFzgTkk7Szo2J3SmSlq78dusyQLzVjCLVLlFRLyaE0eXAx3LO0bEW6T3ZPuyU9eTKs7+0lgwEXF5RPSJiAU2CzczMzMzMzNr7ZxQqs+9wEqSBpYaJPUs7RVU0Bl4Ie9RdDDQLvddD3gxIq4gJY565/2BlouIEcBp5IRHjUYCx0haIY+/saRVGrsgIp4EJgJnlr6xLO/LtFcTc3UCXshzlS+9a5SkDYCnIuIC4FagZ0RcXEiEPV/DMGOBvSW1l9QR+GoN17yZ4y45DzhV0qaFtpWrxLw8aa+pJ8tOjQHOBq6rYX4zMzMzMzOzNskJpTpERAD7AbtKelLSLFJy4b9lXS8BDpU0DdiEj6uF+gHTJE0h7a10PtAVGJ2Xrf0J+HEdIQ0lbbo9OW/U/Xtq++a+I0jfTPevfN0w0r5PjfkpaVndWOCxOmKEtKn4zHyPPYBrqvQbIOnZws86pRMRMYG0l9R04G/ADGBOE/PeB2xW2pQ7ImYAPwCuyZt7jwU2Bf5cuKa0h9L0PMcnNt6O5FcR8UpNd25mZmZmZmbWBinlSMyWfpI6RsRb+RvmHgAGRkRTm2y3uM936hSXf6GewjNb1jTcff9HxxPHjabPtv1aLpilkJ9JZX4uVg9/Xqwe/rxYrfxZsXr489J6dWmvSZW2c6mlmsVsaXG5pM1I+zdd3RqSSWZmZmZmZmZtkRNK1mpExLdbOgYzMzMzMzMz8x5KZmZmZmZmZmZWJyeUzMzMzMzMzMysLl7yZra4rb32JzZdNjMzMzMzM2vtXKFkZmZmZmZmZmZ1cULJzMzMzMzMzMzq4oSSmZmZmZmZmZnVxXsomS1mc+fM548/+WtLh2GtyKO3/5WDf7l3S4dhZmZmZmZWlSuUzMzMzMzMzMysLk4omZmZmZmZmZlZXZxQMjMzMzMzMzOzujihZGZmZmZmZmZmdXFCyRolaZ6kqZJmSvqrpC7NNO4ASRc1x1hl446W9HiOeaqk/Zt7jjxPN0nfXhxjm5mZmZmZmS3tnFCypsyNiIaI6AG8Bhzb0gHV4KAcc0NE3FjLBZLq/cbDboATSmZmZmZmZrZMckLJ6vEg0BVA0laSHpQ0RdI4SZ/P7QMk3STpLkn/lHRe6WJJh0l6QtJ4YLtCezdJ90qaLukeSevm9mGSLpX0kKSnJPWTdKWkRyUNqzVoSZ+WdEse/yFJPXP7YEl/lDQW+KOkNSSNkDQh/2yX+32pUPE0RVIn4Bxgh9x24qI+WDMzMzMzM7PWpN6qDFtGSWoH7AL8ITc9BuwQER9K2hX4JfCNfK4B+ALwHvC4pAuBD4EzgS2BOcB9wJTc/0Lg6oi4WtJ3gQuAffO5TwHbAPsAt5ESUUcAEyQ1RMTUCuFeK2luPt4FGAxMiYh9Je0MXJNjBNgM2D4i5kr6M/DbiPhHTmqNBDYFBgHHRsRYSR2Bd4FTgEER8dXan6KZmZmZmZlZ2+CEkjWlg6SppMqkR4G7c3tn4GpJ3YEAVihcc09EzAGQ9AiwHrA6MDoiXs7tw4GNc/9tgK/n4z8C5xXG+mtEhKQZwIsRMSNfP4u07GxqhZgPioiJpReSticnuyLiXkmrSVo1n74tIkrJp12BzSSVLl01J5DGAr+RdC1wU0Q8W+hTkaSBwECAz625UaN9zczMzMzMzFobL3mzpsyNiAZSUkh8vIfSz4H78t5KewPtC9e8Vziex6IlLktjzS8bd/4ijlvyduF4OeCLhf2XukbEWxFxDqkqqgMwVtImTQ0aEZdHRJ+I6NMMMZqZmZmZmZktVZxQsppExDvA94H/yxtYdwaey6cH1DDEw8CXcnXQCsABhXPjgG/m44OAMc0S9MfG5HGR1A94JSLeqNBvFHB86YWkhvx7w4iYERHnAhOATYA3gU7NHKeZmZmZmZlZq+CEktUsIqYA04FvkZalnS1pCjVUCkXEC6S9jB4kLSF7tHD6eOAwSdOBg4EfNG/kDAa2zOOfAxxapd/3gT558+5HgKNz+wmSZubrPwD+RnoO8yRN86bcZmZmZmZmtqzxHkrWqIjoWPZ678LLjQvHp+Xzw4Bhhf5fLRxfBVxVYY5/AztXaB9QOH4a6FHpXNk1/Sq0vcbHm3wX2weXvX4F6F+h3/HlbdkCMZuZmZmZmZktC1yhZGZmZmZmZmZmdXFCyczMzMzMzMzM6uKEkpmZmZmZmZmZ1cUJJTMzMzMzMzMzq4s35TZbzDp0Xo6Df7l30x3NgInjRtNn234tHYaZmZmZmVmjXKFkZmZmZmZmZmZ1cULJzMzMzMzMzMzq4oSSmZmZmZmZmZnVxXsomS1mb73yEhcdvn9Lh2GtyEN/uIjj/nBjS4dhZmZmZmZWlSuUzMzMzMzMzMysLk4omZmZmZmZmZlZXZxQMjMzMzMzMzOzujihZGZmZmZmZmZmdXFCaSFJmidpqqRpkiZL2ja3ry1pie6mK2mYpNmFeHZpon83STOXVHwLS9Ln8n19Or/+VH7dLb/uLul2SU9KmiTpPkk75nMDJL2cn8ksSTdKWrkZY2uQ9JXmGs/MzMzMzMysNXFCaeHNjYiGiOgF/Bg4GyAino+IZvlKL0nt6uh+UkQ0ACcAlzXH/C0tIp4BLgXOyU3nAJdHxNOS2gN35NcbRsSWwPHABoUhhuf3aHPgfaB/M4bXADihZGZmZmZmZsskJ5Sax6rA6/DJ6p9cJXOTpLsk/VPSeaULJF0qaWKunjmz0P60pHMlTQZOyb9L57oXX1fxINA1928naYikCZKmSzqqvHO1PpKul7RXod8wSfvn+xuTq7KKlVn9JI3OlUCPSbpWkvK5vpLG5eqp8ZI61RJb9lvgi5JOALYHfpXbDwIejIjbSh0jYmZEDKtwj8sDq/DJ9+jePO89ktZtov0ASTNz/A9IWhH4GdA/V0A1Z6LKzMzMzMzMbKm3fEsH0Ip1kDQVaA+sBexcpV8D8AXgPeBxSRfmyptTI+K1XIV0j6SeETE9X/NqRPQGkLSrpIaImAocBlzVRFx7Arfk48OBORHRV9JKwFhJo4Ao9K/WZzhwIHBHTqDsAhwDCNgtIt6V1B24DuiTx/oCsDnwPDAW2E7S+DxW/4iYIGlVYG61eSNidvFmIuIDSScBdwG7R8QH+dTmQFPJtf6Stie9P08Af83tFwJXR8TVkr4LXADs20j76cAeEfGcpC4R8b6k04E+EXFcEzGYmZmZmZmZtTmuUFp4pSVvm5CSONeUKnLK3BMRcyLiXeARYL3cfmCuNppCSo5sVrhmeOF4KHBYTjz1B/5cJZ4hkp7I58/NbbsDh+TE18PAakD3suuq9fkbsFNO9nwZeCAi5gIrAFdImgHcUBb3+Ih4NiLmA1OBbsDngRciYgJARLwRER/WGFvJl4EXgB5VziPp5lxFdFOheXheBvhZYAZwUm7fho+f4x9JlU+NtY8Fhkk6EqhpGaKkgbkCbWIt/c3MzMzMzMxaEyeUmkFEPAisDqxR4fR7heN5wPKS1gcGAbtERE/SXkDtC/3eLhyPICVUvgpMiohXq4RxUkRsDJwMXJnbBByfE18NEbF+RIwqu65in5wAGw3sQUpklZJcJwIvAr1IlUkrNnavVWKtOq+kX+RlZFMhbX4N7AZ8EThR0lr5+llA79JgEbEfMAD4dPlEERGk6qQdG4mnqog4GjgN+BwwSdJqNVxzeUT0iYg+TfU1MzMzMzMza22cUGoGkjYhVa5US/aUW5WUNJojaU1SwqiinNgZSdqcuqnlbgAXActJ2iNfd4ykFXKcG0tapax/Y32Gk5bZ7UBacgbQmVRxNB84mKYrdh4H1pLUN4/fKe9pVHHeiDi1lGTKFV+XAidExH+AIXy8h9KfSUvq9inM1di3uG0PPJmPxwHfzMcHAWMaa5e0YUQ8HBGnAy+TEktvAp2auHczMzMzMzOzNsl7KC280h5KkKptDo2IeZVXvX1SREyTNAV4DHiGtKSqMdcC+wHl1UWVxg5JZwE/IlX2dAMm5+TMy6Q9gYqGNtJnFGnp160R8X5uuwQYIekQUpLpbRqR9xvqD1woqQNp/6Rdm5i35EjgPxFxd2HuwyR9KSLul/RV4DeSfkeqmnoTOKtwfWkPpeWAZ0kVTJC+De6qvDfTy6SkWWPtQ/J+UQLuAaYB/yFtmj4VODsiissUzczMzMzMzNo0pdVAtjSTNAjoHBE/belYrH5dV/tUfO/Lu7R0GNbKHPeHG1s6hKXGxHGj6bNtv5YOY6nj52L18OfF6uHPi9XKnxWrhz8vrVeX9ppUaTsXVygt5STdDGxI9W+RMzMzMzMzMzNbopxQWsrlzabNzMzMzMzMzJYa3pTbzMzMzMzMzMzq4gols8Ws4+qf8X44VjOvLTczMzMzs9bAFUpmZmZmZmZmZlYXJ5TMzMzMzMzMzKwuTiiZmZmZmZmZmVldnFAyMzMzMzMzM7O6eFNus8Vshbfg+V/d29JhWCuxNvD8uMqfl7UH7bxkgzEzMzMzM6vCFUpmZmZmZmZmZlYXJ5TMzMzMzMzMzKwuTiiZmZmZmZmZmVldnFAyMzMzMzMzM7O6tPqEkqR5kqZKmiZpsqRtc/vakm5cwrEMkzS7EM8uTfTvJmnmkopvUUgaLOm5fG+PSPpWM479tKTVm2u8wrjXSZou6cTmHjuP36/0eTMzMzMzMzNblrSFb3mbGxENAJL2AM4GvhQRzwP7N8cEktpFxLwau58UETdK2gm4HOjeHDEsJX4bEb+S1B2YJOnGiPigpYOqRNJngb4RsVEd1ywfER/WMU0/4C1gXJ3hmZmZmZmZmbVqrb5CqcyqwOvwyeofSQMk3STpLkn/lHRe6QJJl0qaKGmWpDML7U9LOlfSZOCU/Lt0rnvxdRUPAl1z/3aShkiakCtmjirvXK2PpOsl7VXoN0zS/vn+xuSqrGJlVj9JoyXdKOkxSddKUj7XV9K4XD01XlKnWmIrFxH/BN4BPlXDMzwzxzdD0ia5fTVJo3L/oYAK1/xQ0sz8c0Ju65bvZZikJ/I97SppbH4/t6oQ5iiga66o2kFSg6SH8j3eLKkU+2hJv5M0EfiBpC0l3S9pkqSRktbK/b6fK7Om5/ekG3A0cGJpjqaem5mZmZmZmVlb0RYqlDpImgq0B9YCdq7SrwH4AvAe8LikCyPiGeDUiHhNUjvgHkk9I2J6vubViOgNkBMYDRExFTgMuKqJuPYEbsnHhwNzIqKvpJWAsZJGAVHoX63PcOBA4A5JKwK7AMeQkjC7RcS7uWLoOqBPHusLwObA88BYYDtJ4/NY/SNigqRVgbnV5o2I2dVuTFJv4J8R8VJuauwZvhIRvSV9DxgEHAGcAfwjIn6Wk2WH53G3zM9263x/D0u6n5Qk3Ag4APguMAH4NrA9sA/wE2DfsjD3AW4vVK9NB46PiPsl/SzHcELuu2JE9JG0AnA/8LWIeFlSf+AXec5TgPUj4j1JXSLif5IuA96KiF9Ve1ZmZmZmZmZmbVFbqFCaGxENEbEJKYlzTakip8w9ETEnIt4FHgHWy+0H5mqjKaQkzGaFa4YXjocCh+WkSX/gz1XiGSLpiXz+3Ny2O3BITnw9DKzGgkvhqvX5G7BTTvZ8GXggIuYCKwBXSJoB3FAW9/iIeDYi5gNTgW7A54EXImICQES8kZd31RJbyYmSZuV+vyi0N/YMb8q/J+U4AHYE/pTjuINcVUZKEN0cEW9HxFv52lLlz+yImJHvaRbp/QxgRmHciiR1BrpExP256eocQ0npff480AO4Oz+P04B18rnpwLWSvgM0uSxO0sBctTWxqb5mZmZmZmZmrU1bqFD6SEQ8qLS58xoVTr9XOJ4HLC9pfVLVTN+IeF3SMFKlU8nbheMRpKqWe4FJEfFqlTBKeygdD1wJbEmqtjk+IkYWO+ZlUx+9rNQn9xsN7EFKZF2fm08EXgR6kRKD7zZ2r1VirTqvpF8AewGUqnz4eA+lfYA/SNqQVBXW2DMsxdJUHE0p3tP8wuv5izgufPw+C5gVEdtU6LMXKQm1N3CqpC0aGzAiLiftoUWPrp+PxvqamZmZmZmZtTZtoULpI3mPnnZAtWRPuVVJyYQ5ktYkVQBVlCubRgKX0vRyN4CLgOWUNgofCRyTl1QhaWNJq5T1b6zPcNJSsB2Au3JbZ1LF0XzgYNJ9N+ZxYC1JffP4nSQtX23eiDg1V341VHgWtwETgUOp4xkWPEBasoakL5P3YgLGAPtKWjnf+365bZFExBzg9cI+RweTlraVexxYQ9I2ObYVJG0uaTngcxFxH3Ay6dl3BN4EOi1qfGZmZmZmZmatTVuoUCrtoQSpwuTQiJhXedXbJ0XENElTgMeAZ0j7DTXmWlKSY1QNY4eks4AfAbuRlmVNzsvxXmbBPX+GNtJnFPBH4NaIeD+3XQKMkHQIKcn0No2IiPfznkAXSupA2j9p1ybmbczPSMv6NiUtdav1GQKcCVyXl8+NA/6TY5ycK5zG535DI2JKWSXXwjoUuEzSysBTpATdJ+RntD9wQV4mtzzwO+AJ4E+5TcAFeQ+lvwI3SvoaqcprkZNfZmZmZmZmZq2B0jY0VgtJg4DOEfHTlo7FWo8eXT8fN3zv0pYOw9qAtQdV+86Btm3iuNH02bZfS4ex1PFzsXr482L18OfFauXPitXDn5fWq0t7TYqIPuXtbaFCaYmQdDOwIdW/Rc7MzMzMzMzMbJnghFKNImK/lo7BzMzMzMzMzGxp0KY25TYzMzMzMzMzs8XPFUpmi9kHHZfdvW+sfl5bbmZmZmZmrYErlMzMzMzMzMzMrC5OKJmZmZmZmZmZWV2cUDIzMzMzMzMzs7o4oWRmZmZmZmZmZnXxptxmi9mbb77Jb88e3NJhWCsy5v7RVc+d+OPBSywOMzMzMzOzalyhZGZmZmZmZmZmdXFCyczMzMzMzMzM6uKEkpmZmZmZmZmZ1cUJpSokfVbS9ZKelDRJ0p2SNpbUTdLMZpznZ5J2zcc7SJolaaqkrpJuXMSxO0r6feEeRkvaemHuQdLRkg5ZlHjyOAMkvZzvsfSzWSP9GyR9ZRHn7CLpe4syhpmZmZmZmZl9zJtyVyBJwM3A1RHxzdzWC1gTeKY554qI0wsvDwLOjog/5df71zqOpOUj4sOy5qHAbKB7RMyXtD6wGfDiQsR5Wb3XNGJ4RBxXY98GoA9wZ/mJKvdcSRfge8AlizCGmZmZmZmZmWWuUKpsJ+CDYhIlIqZFxJhip1zpM0bS5PyzbW5fS9IDufpmZq48aidpWH49Q9KJue8wSftLOgI4EPi5pGuLVUT52iGSJkiaLumo3N4vz38b8EhZbBsCWwOnRcT8fA+zI+KO3KWdpCtyRdQoSR3ydUfmeaZJGiFp5dw+WNKgfDxa0rmSxkt6QtIOuX3z3DY1x9m91gcuaT9J9yhZK4+7LvAzoH8es3+O44+SxgJ/rPYelDkH2DCPMaT8uVV7vjmukwrtZ+a2VSTdkZ/RTEn9a71PMzMzMzMzs7bAFUqV9QAm1dDvJWC3iHg3J0+uI1XTfBsYGRG/kNQOWJlUadM1InpAWoZVHCgihkraHrg9Im6U1K1w+nBgTkT0lbQSMFbSqHyuN9AjImaXxbY5MDUi5lWJvTvwrYg4UtJfgG8AfwJuiogrcoxn5bkvrHD98hGxVV6OdgawK3A0cH5EXCtpRaBdlbn753st2SYibpb0DeBYYE/gjIj4j6TTgT6liiZJg0lVVttHxNyc8Kr0HhSdkp9RQx6jX/G5SRpI5efbPf9sBQi4TdKOwBrA8xGxVx6vc5X7NDMzMzMzM2uTnFBaNCsAF0lqAOYBG+f2CcCVklYAbomIqZKeAjaQdCFwBzCq0oBV7A70lFRaAteZlOh4HxhfIZlUi9kRMTUfTwK65eMeOZHUBegIjKxy/U0Vrn0QOFXSOqTE1D+rXFttydvxwEzgoYi4rpHYb4uIufm42nvQlOJzq/Z8d88/U3J7x9w+Bvi1pHNJCcBPVK4B5CTVQIC11lqrxpDMzMzMzMzMWgcveatsFrBlDf1OJO1H1ItUFbMiQEQ8AOwIPAcMk3RIRLye+40mVfIMrSMeAcdHREP+WT8iSgmptxu5h165QqqS9wrH8/g4uTgMOC4itgDOBNo3cf1H10bEn4F9gLnAnZJ2lnSsPt58e+3Gb5N1gPnAmpIa+2wW77nie1CD4hjVnq9Ie1qV2jeKiD9ExBOkCqcZwFm5iuoTIuLyiOgTEeXVUmZmZmZmZmatnhNKld0LrJSrTACQ1LO0V1BBZ+CFvEfRweQlXpLWA17MS8eGAr0lrQ4sFxEjgNNICYlajQSOyRVPKH3b3CqNXRARTwITgTMlKV/XTdJeTczVCXghz3VQHTEiaQPgqYi4ALgV6BkRFxcSMs83cu3ywJXAt4BHgR/mU2/mmKqp+B6UaWqMas93JPBdSR1ze1dJn8mJsXfy5ulDqO+9NDMzMzMzM2v1vOStgogISfsBv5N0MvAu8DRwQlnXS4ARkg4B7uLjqpd+wEmSPgDeAg4BugJXFSpvflxHSENJy8om5+TQy8C+NVx3BPBr4F+S5gKvACc1cc1PgYfzHA/TeCKm3IHAwfm+/wv8skq/8j2Uvkfag2lMRPxD0jRggqQ7gPuAUyRNBc6uMFa19+AjEfGqpLFKm5z/jbTksKji842IUZI2BR7MObm3gO8AGwFDJM0HPgCOaeyhmJmZmZmZmbU1ioiWjsGsTVt77bVj4MCBTXc0q8GJPx7c0iEscRPHjabPtv1aOoyljp+L1cOfF6uHPy9WK39WrB7+vLReXdprUqXtXLzkzczMzMzMzMzM6uKEkpmZmZmZmZmZ1cUJJTMzMzMzMzMzq4sTSmZmZmZmZmZmVhd/y5vZYtapU6dlciNlWzjerNDMzMzMzFoDVyiZmZmZmZmZmVldnFAyMzMzMzMzM7O6OKFkZmZmZmZmZmZ18R5KZovZhx8+y8jbtmrpMKwVGXnbwl+7xz7jmy8QMzMzMzOzKlyhZGZmZmZmZmZmdXFCyczMzMzMzMzM6uKEkpmZmZmZmZmZ1cUJJTMzMzMzMzMzq4sTSs1E0mclXS/pSUmTJN0paWNJ3STNbMZ5fiZp13y8g6RZkqZK6irpxkUcu6Ok3xfuYbSkrRfmHiQdLemQRYynU46le369gqQZkrbOr9eU9GdJT+V4H5S0Xz7XT9Kc/GymS/q7pM8sSjxlsXWT9O3mGs/MzMzMzMysNXFCqRlIEnAzMDoiNoyILYEfA2s291wRcXpE/D2/PAg4OyIaIuK5iNi/jpgrfcPfUOA1oHu+h8OA1Rcyzssi4pqFubYwxpuk53hRbhoEjIuIh/MzvwV4ICI2yPF+E1inMMSY/Gx6AhOAYxclnjLdACeUzMzMzMzMbJnkhFLz2An4ICIuKzVExLSIGFPslKtaxkianH+2ze1rSXogV9PMzJVH7SQNy69nSDox9x0maX9JRwAHAj+XdG2xiihfO0TShFydc1Ru75fnvw14pCy2DYGtgdMiYn6+h9kRcUfu0k7SFbkiapSkDvm6I/M80ySNkLRybh8saVA+Hi3pXEnjJT0haYfcvnluK1URdS9/sBHxl9z3R8DRpAQTwM7A+2XP/N8RcWH5GDn51Al4Pb/+tKRb8pwPSerZRPuXcoxTJU2R1Ak4B9ght51Y8VNhZmZmZmZm1kZVqlKx+vUAJtXQ7yVgt4h4NydPrgP6kCpdRkbELyS1A1YGGoCuEdEDQFKX4kARMVTS9sDtEXGjpG6F04cDcyKir6SVgLGSRuVzvYEeETG7LLbNgakRMa9K7N2Bb0XEkZL+AnwD+BNwU0RckWM8K8+9QFIHWD4itpL0FeAMYFdSguj8iLhW0opAuypz/wB4FBgYEa8V4p1cpX/JDpKmAqsBbwM/ye1nAlMiYl9JOwPXkJ53tfZBwLERMVZSR+Bd4BRgUER8tYkYzMzMzMzMzNocVygtWSsAV0iaAdwAbJbbJwCHSRoMbJGXej0FbCDpQkl7Am/UMc/uwCE5mfIwKaFSqv4ZXyGZVIvZETE1H08iLfkC6JGrnmaQluBtXuX6mypc+yDwE0knA+tFxNwq1+4JvEBK3FUk6eJcJTWh0Fxa8vY54CrgvNy+PfBHgIi4F1hN0qqNtI8FfiPp+0CXiPiwWhyFeAZKmihpYlN9zczMzMzMzFobJ5Saxyxgyxr6nQi8CPQiVSatCBARDwA7As8BwyQdEhGv536jSZU8Q+uIR8DxOZnSEBHrR0SpQuntRu6hV66QquS9wvE8Pq5uGwYcFxFbkCp82jdx/UfXRsSfgX2AucCdknaWdGxhednaktYGvg9sBXyltAwtx9u7NHhEHAvsAqxRZf7bSM+4bhFxDnAE0IFU7bVJDddcHhF9IqLPwsxpZmZmZmZmtjRzQql53AusJGlgqUFSz9JeQQWdgRfyHkUHk5d4SVoPeDEvHRsK9Ja0OrBcRIwATqOQPKnBSOAYSSvk8TeWtEpjF0TEk8BE4My851Bpz6e9mpirE/BCnuugOmJE0gbAUxFxAXAr0DMiLi4kwp4Hfgv8MiKeBX4IXJzjuxdoL+mYwpArNzLd9sCT+XhMKVZJ/YBXIuKNau2SNoyIGRFxLqmabBPgzXzvZmZmZmZmZsscJ5SaQUQEsB+wq9LX3M8Czgb+W9b1EuBQSdNISYlStVA/YJqkKUB/4HygKzA6L1v7Ex9vRl2LoaRNtyfnjbp/T237ZR1B+ma6f+XrhpH2fWrMT0nL6sYCj9URI6RNxWfme+xB2rPoI5J2A9YF/gAQEX8lbax9SH7m+wJfkjRb0njgauDkwhClTbOnkRJ4/5fbBwNbSppO2lz70CbaT1DaHH068AHwN2A6MC8vs/Om3GZmZmZmZrZMUfq73MwWlw03XCXOPqfa1lJmzWuPfca3dAjNbuK40fTZtl9Lh7HU8XOxevjzYvXw58Vq5c+K1cOfl9arS3tNqrSdiyuUzMzMzMzMzMysLk4omZmZmZmZmZlZXZxQMjMzMzMzMzOzujihZGZmZmZmZmZmdanlm7/MbBEsv/w6bXKjZFs8vFmhmZmZmZm1Bq5QMjMzMzMzMzOzujihZGZmZmZmZmZmdXFCyczMzMzMzMzM6uI9lMwWs2c+DHb868iWDsNak0X8vDyw9x7NFIiZmZmZmVllrlAyMzMzMzMzM7O6OKFkZmZmZmZmZmZ1cULJzMzMzMzMzMzq4oSSmZmZmZmZmZnVxQmlhSTprTr6DpY0qDnGlzRP0lRJMyXdIGnlesZdEiQNkLR2lXPdJM3N91D6OaSRsbpI+l4zxHTC0viszMzMzMzMzFojJ5Ran7kR0RARPYD3gaMX52SSFuabAAcAFRNK2ZP5Hko/1zTStwtQMaFUZ2wnABUTSpLa1TGOmZmZmZmZ2TLPCaVmJGlvSQ9LmiLp75LWLJzuJelBSf+UdGThmpMkTZA0XdKZdU45BthI0qcl3ZLHeEhSzzz2jFzhI0mvliqBJF0jaTdJ7SQNKcx/VD7fT9IYSbcBj0haRdIdkqblyqj+ud+Wku6XNEnSSElrSdof6ANcm6uPOtT47NbLz2Z1Scvl+XcHzgE2zGMNKY8tX3tLjmGWpIEVxv4+KcF1n6T7cttbkn4taRqwjaTvSBqf5/l9Kckkaff8vk3OFWEdc/s5kh7Jz+1Xdb5vZmZmZmZmZq3awlSfWHX/AL4YESHpCOBHwP/lcz2BLwKrAFMk3QH0ALoDWwECbpO0Y0Q80NREuTrny8BdwJnAlIjYV9LOwDVAAzAW2A74N/AUsEM+tw1wDHA4MCci+kpaCRgraVSeojfQIyJmS/oG8HxE7JXn7ixpBeBC4GsR8XJOMv0iIr4r6ThgUERMrBL+hpKmFl4fHxFjJJ0LXAqMBx6JiFGSnshxNOS5+xVjy9d/NyJey8mrCZJGRMSrpcEj4gJJPwR2iohXcvMqwMMR8X+SNgVOBraLiA8kXQIcJOlO4DRg14h4W9LJwA8lXQzsB2yS3+sujb5ZZmZmZmZmZm2ME0rNax1guKS1gBWB2YVzt0bEXGBurpLZCtge2B2Ykvt0JCWYGksodSgkY8YAfwAeBr4BEBH3SlpN0qr5/I6khNKlwEBJXYHXc4Jkd6BnrioC6Jznfx8YX0jYzAB+nRM+t+fkTw9SQuxuSQDtgBdqfE5PlhJERRExVNIBpGV8C5wvKMYG8H1J++Xjz+V7eHXByz5hHjAiH+8CbElKRgF0AF4iJQA3IyXaIL2nDwJzgHeBP0i6Hbi9fPBcKTUQoMMG3ZsIxczMzMzMzKx1cUKpeV0I/CYibsuVNIML56Ksb5Cqks6OiN/XMcfc8mRMTnZU8gBwLLAucCqpqmZ/UqKJPP/xETGybLx+wNsfBRrxhKTewFeAsyTdA9wMzIqIbRoLVtLWQOn+TgemN9J3ZVJSDlJy7c0qXT+KLce6K7BNRLwjaTTQvrGYsncjYl5pGODqiPhxWTx7A3dHxLcqxLoVKRG1P3AcsHPxfERcDlwOsPKGG5e/92ZmZmZmZmatmvdQal6dgefy8aFl574mqb2k1YB+wARgJPDdwr48XSV9ZiHmHQMclMfoB7wSEW9ExDPA6kD3iHiKtCRvEB9XQI0EjsnL15C0saRVygdX+sa2dyLiT8AQ0pKzx4E1JG2T+6wgafN8yZtAJ4CIeLiw+fZtTdzHucC1pMTTFeVjVdGZVHH1jqRNSFVFlTQ2zj3A/qVnr7Qn1XrAQ8B2kjbK7avkZ9QR6BwRdwInAr2auC8zMzMzMzOzNsUVSgtvZUnPFl7/hlSRdIOk14F7gfUL56cD95ESPD+PiOeB5/P+PQ/mKqO3gO+QllvVYzBwpaTpwDt8Mpn1MGk5GqTE09mkxBLAUKAbMFkpgJeBfSuMvwUwRNJ84APgmIh4Py+Vu0BSZ9Jn6XfALGAYcJmkuaTKobll45XvoXQlMA3oS9rHaJ6kb0g6LCKukjRW0kzgb8AdZWPdBRwt6VFSkuuhKs/ocuAuSc9HxE7FExHxiKTTgFGSlsv3eGxEPCRpAHBd3mMK0p5KbwK3SmpPqm76YZU5zczMzMzMzNokJ5QWUkRUq+66tULfwY2Mcz5wfoX2jlX6L9AeEa9RORFERBxcOB5HoSotIuYDP8k/RaPzT6nfSFI1U/nYU0l7NJW3j+Dj/YnKzz1N2qOoki8W+n29cPztCvGVzr1H2py8URFxIWlJYul1x7Lzw4HhFa67l5ToKrdVU3OamZmZmZmZtVVe8mZmZmZmZmZmZnVxQsnMzMzMzMzMzOrihJKZmZmZmZmZmdXFeyiZLWafW148sPceLR2GtRITx42mz7b9WjoMMzMzMzOzRrlCyczMzMzMzMzM6uKEkpmZmZmZmZmZ1cUJJTMzMzMzMzMzq4sTSmZmZmZmZmZmVhdvym22mD075312Pu2alg7DWpM7m//zcu9ZhzT7mGZmZmZmtuxyhZKZmZmZmZmZmdXFCSUzMzMzMzMzM6uLE0pmZmZmZmZmZlYXJ5TMzMzMzMzMzKwubSqhJOmzkq6X9KSkSZLulLSxpG6SZjbjPD+TtGs+3kHSLElTJXWVdOMijt1R0u8L9zBa0tYLcw+Sjpa0yDvxShog6eV8j49JOnFRxyyMPVpSn+YarzDukPy+DGnusfP4DZK+sjjGNjMzMzMzM1vatZlveZMk4Gbg6oj4Zm7rBawJPNOcc0XE6YWXBwFnR8Sf8uv9ax1H0vIR8WFZ81BgNtA9IuZLWh/YDHhxIeK8rN5rGjE8Io6TtBrwuKQbI6JZn2szGwh8OiLm1dK5ynvRmAagD3DnQsRmZmZmZmZm1qq1pQqlnYAPikmUiJgWEWOKnXKlzxhJk/PPtrl9LUkP5CqcmbnyqJ2kYfn1jFJlTm7bX9IRwIHAzyVdW6wiytcOkTRB0nRJR+X2fnn+24BHymLbENgaOC0i5ud7mB0Rd+Qu7SRdkStvRknqkK87Ms8zTdIISSvn9sGSBuXj0ZLOlTRe0hOSdsjtm+e2qTnO7o095Ih4FfgXsFa+/vQ890xJl+fEXmPzdchVZI9KuhnoULj/b+XnPFPSuYX2twoVR3+XtFUe/ylJ+5THmJ9tR2CSpP75fbk33989ktYtvI+XSXoYOE/ShpLuypVhYyRtkvsdkGOalj8jKwI/A/rn59a/sWdmZmZmZmZm1ta0pYRSD2BSDf1eAnaLiN5Af+CC3P5tYGRENAC9gKmkKpSuEdEjIrYArioOFBFDgduAkyLioLJ5DgfmRERfoC9wZK42AugN/CAiNi67ZnNgaiNVNd2BiyNic+B/wDdy+00R0TciegGP5rkrWT4itgJOAM7IbUcD5+f77gM8W+VaAHIypj0wPTddlOfuQUoOfbWJ+Y4B3omITXPblnnctYFzgZ1Jz72vpH3zNasA9+b7fhM4C9gN2I+U2PmEiNgHmBsRDRExHLiQVLnWE7iWj99zgHWAbSPih8DlwPERsSUwCLgk9zkd2CM/330i4v3cNrwwh5mZmZmZmdkyo80seavDCsBFkhqAeUApqTMBuFLSCsAtETFV0lPABpIuBO4ARtUxz+5AT0mlJXCdSQmh94HxETF7IWKfHRFT8/EkoFs+7iHpLKALqTJnZJXrb6pw7YPAqZLWISWm/lnl2v6SdgQ2AY6LiHdz+06SfgSsDHwamAX8tZH5diQndCJiuqRSYqovMDoiXgaQdG3uewvpmd2V+80A3ouIDyTNKIzbmG2Ar+fjPwLnFc7dEBHzJHUEtgVuyEVWACvl32OBYZL+UrinRkkaSFp2x8pr1hKimZmZmZmZWevRliqUZpGrXZpwImk/ol6kipwVASLiAVIC4zlS8uCQiHg99xtNquQZWkc8IlW7NOSf9SOilJB6u5F76CWpXZXz7xWO5/FxQnAYKcmzBXAmqYKoses/ujYi/gzsA8wF7pS0s6Rj81KuqblyCFI1Tk9S0uUcpQ3Q25OqePbPc19RNvcC8y2kDyIi8vH80rh5WeCiJkVL78VywP8K71dDrqIiIo4GTgM+R1pGt1pTg0bE5RHRJyKafcNxMzMzMzMzs5bWlhJK9wIr5coQACT1LO3dU9AZeCEnIw4G2uW+6wEvRsQVpMRRb0mrA8tFxAhSQqF3HfGMBI7JFU8ofdvcKo1dEBFPAhOBMwt7EXWTtFcTc3UCXshzlS+9a5SkDYCnIuIC4FagZ0RcXEiqPF8W40RSlc8P+Dh59Equ8KllQ/IHSMsLkdQD6JnbxwNfkrR6Tqh9C7i/nntpxDjgm/n4IGBMeYeIeAOYLemAHJuUNnVH0oYR8XDejP1lUmLpTdJzNzMzMzMzM1vmtJmEUq5g2Q/YVdKTkmYBZwP/Let6CXCopGmk5VulCpV+wDRJU0h7K50PdAVGS5oK/An4cR0hDSVtuj1ZaaPu31NbNc0RpG+m+1e+bhhp36fG/BR4mLQ067E6YoS0qfjMfI89gGtquOZc4DBS5dEVwExSAm1CDddeCnSU9Chp/6NJABHxAnAKcB8wDZgUEbfWdSfVHQ8clpfXHUxKhlVyEHB4/mzMAr6W24eUNgsnJaem5Tg386bcZmZmZmZmtizSxyuJzGxxWOWz68cmB5/Z0mHYMu7esw5p6RAW2sRxo+mzbb+WDmOp4+di9fDnxerhz4vVyp8Vq4c/L61Xl/aaVGk7lzZToWRmZmZmZmZmZkuGE0pmZmZmZmZmZlYXJ5TMzMzMzMzMzKwui/qV62bWhHU6r9iq96+xJctry83MzMzMrDVwhZKZmZmZmZmZmdXFCSUzMzMzMzMzM6uLE0pmZmZmZmZmZlYXJ5TMzMzMzMzMzKwu3pTbbDFb6a3/MOfcLVo6DGslugNzxiyZuTqfPGPJTGRmZmZmZm2OK5TMzMzMzMzMzKwuTiiZmZmZmZmZmVldnFAyMzMzMzMzM7O6LBMJJUlv1dF3sKRBzTG+pHmSpkqaKekGSSvXM+6SIGmApLWrnOsmaW6+h0ckXSNphWaat+7nXOO4T0uakWOeKmnb5p4jz9Mg6SuLY2wzMzMzMzOzpd0ykVBqQXMjoiEiegDvA0cvzskkLcwm6wOAigml7MmIaAC2ANYBDlyIOZa0nfJzb4iIcbVcsBDPrgFwQsnMzMzMzMyWSctsQknS3pIeljRF0t8lrVk43UvSg5L+KenIwjUnSZogabqkM+uccgywkaRPS7olj/GQpJ557BmSuih5VdIhuf0aSbtJaidpSGH+o/L5fpLGSLoNeETSKpLukDQtV0b1z/22lHS/pEmSRkpaS9L+QB/g2lzN06Fa8BExDxgPdG3s+eXKoysljZb0lKTvF57fqZKekPQP4POF9ob8LKZLulnSp3L7aEm/lTRR0qOS+kq6Kb8vZ9X64HOl1b15/HskrZvbh0m6TNLDwHmSNpR0V35GYyRtkvsdkJ/lNEkPSFoR+BnQPz+3/rXGYmZmZmZmZtYWLLMJJeAfwBcj4gvA9cCPCud6AjsD2wCnS1pb0u6kb/TeilSdsqWkHWuZKFe/fBmYAZwJTImInsBPgGtyt7HAdsDmwFPADrl9G2AccDgwJyL6An2BIyWtn/v0Bn4QERsDewLPR0SvXBl1V16mdiGwf0RsCVwJ/CIibgQmAgflap65jdxDe2Br4K4ant8mwB75WZ0haQVJWwLf5OPKnr6F/tcAJ+dnMgM4o3Du/YjoA1wG3AocC/QABkharUq49+VEz8P59YXA1Xn8a4ELCn3XAbaNiB8ClwPH52c0CLgk9zkd2CMiegH7RMT7uW14fm7Dqz03MzMzMzMzs7ZoYZZItRXrAMMlrQWsCMwunLs1J1fmSrqPlBjZHtgdmJL7dCQlmB5oZI4Okqbm4zHAH4CHgW8ARMS9klaTtGo+vyPwb+BSYKCkrsDrEfF2Tmj1zFVFAJ3z/O8D4yOiFP8M4NeSzgVuj4gxknqQkjB3SwJoB7xQ43PaMN/D+sAdETE9tzf2/O6IiPeA9yS9BKxJSpDdHBHvAOSKKiR1BrpExP352quBGwpj3Va4r1kR8UK+7ingc8CrFWLeKSJeKbzeBvh6Pv4jcF7h3A0RMU9SR2Bb4Ib8jABWyr/HAsMk/QW4qcJ8C5A0EBgIsMXa7Wu5xMzMzMzMzKzVWJYrlC4ELoqILYCjgOJf/VHWNwABZxf25tkoIv7QxBxzC/2Pz5Ut1TxASrrsAIwGXgb2JyWayPMfXxhv/YgYlc+9/VGgEU+QKpZmAGdJOj1fO6tw7RYRsXt5AJK21sebWe+Tm0t7KG1IqsoqtTf2/N4rHM9j0RKXpbHml407fxHHLSk9u+WA/xWeUUNEbAoQEUcDp5ESWJMaqYz6SERcHhF9cnWVmZmZmZmZWZuyLCeUOgPP5eNDy859TVL7nDjoB0wARgLfzZUsSOoq6TMLMe8Y4KA8Rj/glYh4IyKeAVYHukfEU6QlZYP4uAJqJHBMXr6GpI0lrVI+uNI3tr0TEX8ChpCSS48Da0jaJvdZQdLm+ZI3gU4AEfFwIZlyW3HcXPFzCvDj3NTY86vkAWBfSR0kdQL2zuPOAV6XVFridzBwf5UxFtY40nI7SM9+THmHiHgDmC3pAAAlvfLxhvnZnE5K9H2OwnMzMzMzMzMzW9YsK0veVpb0bOH1b4DBpOVNrwP3kpZ0lUwH7iMleH4eEc8Dz0vaFHgwL4l6C/gO8FKdsQwGrpQ0HXiHTyZjHiYtR4OU9DiblFgCGAp0AyYrBfAysG+F8bcAhkiaD3wAHBMR7+elchfkJWbLA78DZgHDgMskzQW2aWwfJeAWYHBO/gym+vNbQERMljQcmEZ6ZhMKpw/NMaxM2j/qsMbGWgjHA1dJOon03KqNfxBwqaTTgBVIe0NNIz3P7qRKr3ty23+AU/JywLO9j5KZmZmZmZktSxRRvrqrrIP0MgsuAasqIhamaseszerZtUPcftRGLR2G2QI6nzyjpUOoycRxo+mzbb+WDmOp4+di9fDnxerhz4vVyp8Vq4c/L61Xl/aaVGk7l1oqlC6mjoSSmZmZmZmZmZm1bU0mlCJi8BKIw8zMzMzMzMzMWomF2kNJ0qdIX0P/OeBvEfG6pPbA+xExvzkDNDMzMzMzMzOzpUtd3/ImaXlJ5wHPkr6J6498vBnzCOCM5g3PzMzMzMzMzMyWNvVWKP0COBI4jvQtaE8Vzt0KHI2TSmaf8F7HdVvN5sfW8rxZoZmZmZmZtQb1JpQOAU6JiKsktSs79ySwQfOEZWZmZmZmZmZmS6u6lrwBXUiJo0pWBMqTTGZmZmZmZmZm1sbUm1CaCXytyrkvA5MXLRwzMzMzMzMzM1va1bvk7SxghKQOwA1AAA2S9gOOAvZp5vjMWr3n5j7HVy7frqXDsNZkZstOf+fAsS0bgJmZmZmZLfXqqlCKiFuBbwO7An8DBAwFBgAHR8TI5g7QzMzMzMzMzMyWLvVWKBERfwH+ImljYHXgNeDxiIjmDs7MzMzMzMzMzJY+dSeUSiLiCeCJZozFzMzMzMzMzMxagSYTSpJOr2fAiPjZwodjZmZmZmZmZmZLu1oqlI4ve90BWDkfvwV0zMfv5B8nlFo5SQH8JiL+L78eBHSMiMGLed7RwKCImFihvWNE9Mmv+wC/ioh+jYzVDdg2Iv7czDF2A26PiB7NOa6ZmZmZmZlZa9LkptwRsUbph/Qtbi8B3wFWiYhVgVWAg3P71xZnsLbEvAd8XdLqzTmokro2gi/4jKQv19G/G2kD+WYjaaGXiJqZmZmZmZm1JfX+cX8B8MuI+HNEzAWIiLkRcS1wDnBxcwdoLeJD4HLgxPITktaQNELShPyzXW4fnCuZSv1mSuqWfx6XdA3py9A/J+lSSRMlzZJ0Zo0xDQFOrRBPO0lDcizTJR2VT50D7CBpqqQTJd0hqWe+ZkppKaekn0k6Mie7huS4Z0jqn8/3kzRG0m3AI2Vzb5DH6lvjPZiZmZmZmZm1CfVWXPQAnq9y7jlg00ULx5YiFwPTJZ1X1n4+8NuI+IekdYGRNP2+dwcOjYiHACSdGhGvSWoH3COpZ0RMb2KMB4H9JO0EvFloPxyYExF9Ja0EjJU0CjiFtHzuq3nOlUgJpn+TEmbb5et3AI4Gvg40AL1I3144QdIDuU9voEdEzM5L3pD0eeB6YEBETGsidjMzMzMzM7M2pd4KpSeAH+Y/zj8iqT3wQ+Dx5grMWlZEvAFcA3y/7NSuwEWSpgK3AatK6kjj/l1KJmUHSpoMTAE2BzarMayzgNPK2nYHDsnxPAysRkpglRsD7EhKJN0BdJS0MrB+RDwObA9cFxHzIuJF4H6gVHk0PiJmF8ZaA7gVOKhaMknSwFyFNbHSeTMzMzMzM7PWrN4KpeOBO4FnJd1N2jfpM8BupI2669njxpZ+vwMmA1cV2pYDvhgR7xY7SvqQTyYo2xeO3y70Wx8YBPSNiNclDSvrW1VE3CvpLOCLxamB4yNiZFk8/counwD0AZ4C7iZVIR0JTKph6rfLXs8B/kNKQj2yYHeIiMtJywbpuG7HqGEOMzMzMzMzs1ajrgqliHiAVP1xFbAWsEf+fRXQPZ+3NiIiXgP+QlpWVjKKwjf/SWrIh0+TloYhqTewfpVhVyUlaOZIWpP6k5BnAT8qvB4JHCNphTz3xpJWIS2L61S4l/eBZ4ADSMvnxpASW6XP7Bigf96TaQ1SNdP4KjG8D+xHqoxq1o2/zczMzMzMzFqDur+1KiJe4JN/0Fvb9mvguMLr7wMXS5pO+vw8QNqDaAQpwTKLtPTsiUqDRcQ0SVOAx0gJnrH1BBMRd0p6udA0lPSNbpMlCXgZ2BeYDsyTNA0YFhG/JSWNdomIuZLGAOvkNoCbgW2AaUAAP4qI/0rapEocb0v6KnC3pLci4rZ67sPMzMzMzMysNVuor0GXtDbpj+9PA68CD0VEtc26rZWJiI6F4xdJyxlLr18B+le4Zi5pP6NKepT1HVBl3n61tEfEloXj+cBP8k+5ncuu+ynw03z8PGm5XOlcACfln+I1o4HRhddPl+4nIv7Hx/ssmZmZmZmZmS0z6koo5W/lupC090y7wql5ki4n7WUzvxnjMzMzMzMzMzOzpUy93/J2JvBdUjVIN6BD/v2T3D64+UIzMzMzMzMzM7OlUb1L3g4BTouIXxXa/gMMkRSk/XVOb67gzMzMzMzMzMxs6VNvhdJnSJsdVzI9nzczMzMzMzMzszas3gqlJ4Bvkr46vtw3gccXOSKzNqZrh67cObCuL7OzZdjEcaPps22/lg7DzMzMzMysUfUmlM4Crpe0LnAj8CKpKukAYCdSUsnMzMzMzMzMzNqwuhJKEfEXSf8DfgacD6wAfABMAvaMiLubPUIzMzMzMzMzM1uq1FuhRESMAkZJWg5YHXglIuY3e2RmZmZmZmZmZrZUajKhJKnJb22TVDqMiPj5ogZl1qY8/zxTd/tSS0dhrcTywNSWDqJMw933t3QIZmZmZma2lKmlQmkwMBd4G1DjXQnACSUzMzMzMzMzszasloTSk8B6pH2Srgduiog3F2tUZmZmZmZmZma21FquqQ4R0R3YFphFqj56UdJNkg6Q1GFxB2hmZmZmZmZmZkuXJhNKABExMSIGRcS6wJ7Af4GLgJckXStpx8UZpJmZmZmZmZmZLT1qSigVRcQDEfE94HPAZUB/4IRmjqvVkvRWHX0HSxrUHONLmidpqqSZkm6QtHI94y4JkgZIWrvKuW6SZlZo/5mkXZsYt+JzlNRF0vfK2rpLul3Sk5ImSbqvlBDN8b2cn+MsSTeWnmOeIyRtVBjrhNzWp7YnYGZmZmZmZtY21J1QkrSdpAuBfwPHADcC5zd3YFa3uRHREBE9gPeBoxfnZJJq2X+r3ACgYkKpmog4PSL+vhBzAXQBPkooSWoP3AFcHhEbRsSWwPHABoVrhufnuDnpOfYvnJsBfLPw+gDSUlAzMzMzMzOzZUpNCSVJvSWdJ+nfwD2k6qQTgc9ExDcjwt8p3QhJe0t6WNIUSX+XtGbhdC9JD0r6p6QjC9ecJGmCpOmSzqxzyjHARpI+LemWPMZDknrmsWfk6h1JelXSIbn9Gkm7SWonaUhh/qPy+X6Sxki6DXhE0iqS7pA0LVdG9c/9tpR0f64AGilpLUn7A32Aa3MFUE37b0kalq9F0lckPZbHvUDS7YWum0kaLekpSd/PbecAG+b5hgAHAQ9GxG2liyJiZkQMqzDv8sAqwOuF5luAr+XzGwJzgFdquQ8zMzMzMzOztqTJhJKkx4GHgJ7AGaQk0r4RcX1EvLO4A2wj/gF8MSK+QPqmvB8VzvUEdga2AU6XtLak3YHuwFZAA7BlrftU5UTIl0nVNGcCUyKiJ/AT4JrcbSywHbA58BSwQ27fBhgHHA7MiYi+QF/gSEnr5z69gR9ExMak/bSej4heuTLqLkkrABcC++cKoCuBX0TEjcBE4KBcATS3lvsp3Fd74PfAl/O4a5R12QTYg/TMzshxnAI8mec7Kd/v5Cam6i9pKvAc8Gngr4VzbwDPSOpBqlQaXs89mJmZmZmZmbUVtVQodQc+BLYEzgP+Jemlaj+LNdrWax1gpKQZQCmxUXJrRMyNiFeA+0gJkd3zzxRSAmQT0vvQmA45ETIR+A/wB2B74I8AEXEvsJqkVUkVTDvmn0uBLSR1BV6PiLfz3Ifk8R4GVivMPz4iZufjGcBuks6VtENEzAE+D/QA7s7Xn5bvf1FtAjxVmPu6svN3RMR7+Tm+BKxJEyTdnCurbio0D4+IBuCzpPs7qeyy60nJpH2BmxsZe6CkiZImNhWHmZmZmZmZWWtTyz449S63sgVdCPwmIm6T1A8YXDgXZX0DEHB2RPy+jjnm5kTIRyRV6/sAcCywLnAqsB+wPynRRJ7/+IgYWTZeP+DtjwKNeEJSb+ArwFmS7iElWWZFxDaNBStpa1LFEcDpwPRG765p7xWO51H5sz2LlEQDICL2yxtq/6q8Y0SEpL+S9lg6p3DqdmAIMDEi3qj2jCPicuBygM936lT+HpuZmZmZmZm1ak0mlCLCCaVF15m0hArg0LJzX5N0Nmm/nn6kZVpzgZ9LujYi3srVQx9ERL0VYGNI+wb9PCeDXomIN4A3JK0OrBgRT0n6BzAIOC5fNxI4RtK9EfGBpI0L8X9E6RvbXouIP0n6H3AEKfmyhqRtIuLBvPRs44iYBbwJdAKIiIdJy/lKY3Vr4l4eBzaQ1C0inuaTm2VX89F82Z+BH0vap7CPUmPfhrc98GSxISLekXQy8EQN85uZmZmZmZm1SQvzTV3WuJUlPVt4/RtSRdINkl4H7gXWL5yfTlrqtjrw84h4Hnhe0qbAg7kC5i3gO6SlXPUYDFwpaTrwDp9MZj0MtMvHY4CzSXs9AQwFugGTlQJ4mbTEq9wWwBBJ84EPgGMi4v28ifYFkjqTPmO/I1UHDQMukzQX2KbCPkqfL3t2J5YOImKupO+R9ml6G5jQ1M1HxKuSxkqaCfwtIk6S9FXgN5J+B7xISjqdVbisv6TtSctBnyV9M135uNc3NbeZmZmZmZlZW+aEUjOLiGr7Ut1aoe/gRsY5Hzi/QnvHKv0XaI+I16icCCIiDi4cj6Own1ZEzCdt4v2TsstG559Sv5GkaqbysadSWFpWaB8BjKgSz9PAChVO3VA4vi8iNslJrotJ+0Ut8BzzBuGl42+XnXuMtESvUgzDSEmvSucGV2nvV6ndzMzMzMzMrC2rZVNus6XFkXmj71mkZYT17DFlZmZmZmZmZs3EFUrWakTEb4HftnQcZmZmZmZmZss6VyiZmZmZmZmZmVldXKFktritvTYNd9/f0lFYKzFx3Gj6bNuvpcMwMzMzMzNrlCuUzMzMzMzMzMysLk4omZmZmZmZmZlZXZxQMjMzMzMzMzOzujihZGZmZmZmZmZmdfGm3GaL2dw58/njT/7a0mFYK/Lo7Uv/5+XgX+7d0iGYmZmZmVkLcoWSmZmZmZmZmZnVxQklMzMzMzMzMzOrixNKZmZmZmZmZmZWlxZNKEn6rKTrJT0paZKkOyVtLKmbpJnNOM/PJO2aj3eQNEvSVEldJd24iGN3lPT7wj2MlrT1wtyDpKMlHbIo8eRxBki6qBnG+ei5VTm/r6TNau2/tJPUR9IFLR2HmZmZmZmZ2dKuxTblliTgZuDqiPhmbusFrAk805xzRcTphZcHAWdHxJ/y6/1rHUfS8hHxYVnzUGA20D0i5ktaH9gMeHEh4rys3msWp7LnVsm+wO3AIzX2r6jKc613jHYRMW9RxoiIicDERRnDzMzMzMzMbFnQkhVKOwEfFJMoETEtIsYUO+VKnzGSJuefbXP7WpIeyJVGM3PlUTtJw/LrGZJOzH2HSdpf0hHAgcDPJV1brCLK1w6RNEHSdElH5fZ+ef7byImTQmwbAlsDp0XE/HwPsyPijtylnaQrckXUKEkd8nVH5nmmSRohaeXcPljSoHw8WtK5ksZLekLSDrl989w2NcfZvdYHLumH+dnMlHRCof2nkh6X9A9J1xViGCZp/3x8jqRH8py/yu/DPsCQHMuGZf37ShqX73G8pE5lsXziuTby/JeTdImkxyTdnavYSnM8nZ/RZOAASbtLejB/Tm6Q1LFS7LntgPwcpkl6oBDT7fn405Juydc8JKln4T26Mr8/T0n6fq3P38zMzMzMzKytaLEKJaAHMKmGfi8Bu0XEuzl5ch3QB/g2MDIifiGpHbAy0AB0jYgeAJK6FAeKiKGStgduj4gbJXUrnD4cmBMRfSWtBIyVNCqf6w30iIjZZbFtDkxtpDKmO/CtiDhS0l+AbwB/Am6KiCtyjGfluS+scP3yEbGVpK8AZwC7AkcD50fEtZJWBNpVe3BFkrYEDiMlwAQ8LOl+0mfgG0AvYAVgMmXvi6TVgP2ATSIiJHWJiP/lZNDtEXFj7lfqvyIwHOgfERMkrQrMrRDWR89V0kAqP/8tgW6kqq/PAI8CVxbGeDUiektaHbgJ2DUi3pZ0MvBDSReXx56vOx3YIyKeK/+cZGcCUyJiX0k7A9eQPl8Am5ASop2AxyVdGhEfVHzwZmZmZmZmZm1QSyaUarUCcJGkBmAesHFunwBcKWkF4JaImCrpKWADSRcCdwCjKg1Yxe5Az1L1C9CZlBB6HxhfIZlUi9kRMTUfTyIlRgB65ERSF6AjMLLK9TdVuPZB4FRJ65ASU/+sMZbtgZsj4m0ASTcBO5Cq1G6NiHeBdyX9tcK1c4B3gT/kCp7bm5jr88ALETEBICLeqNKv+FyrPf/tgRtyBdh/Jd1XNsbw/PuLpKTT2JzYWpH0rKrFPhYYlhN9N7Gg7UmJNiLiXkmr5cQYwB0R8R7wnqSXSMs0ny1enBNkAwE+t+ZGVW7fzMzMzMzMrHVqySVvs0jVJ005kbQfUS9SZdKKABHxALAj8BwpMXBIRLye+40mVfIMrSMeAcdHREP+WT8iSgmptxu5h165QqqS9wrH8/g4gTcMOC4itiBVwrRv4vqPro2IP5OWms0F7pS0s6Rj87KzqZLWbvw265f3N9oKuBH4KnBXMw1dfK6NPf9axhBwd+H6zSLi8GqxR8TRwGnA54BJuQqrVtXe149ExOUR0Sci+tQxrpmZmZmZmVmr0JIJpXuBlXIlBwCSeirvFVTQmVTtMh84mLzES9J6wIt56dhQoLTsabmIGEFKFvSuI56RwDG54gmlb5tbpbELIuJJ0ibOZyqXxSjty7RXE3N1Al7Icx1UR4xI2gB4KiIuAG4FekbExYVEyvNVLh0D7Ctp5Xxf++W2scDektrnPYe+WmHOjkDniLiTlODrlU+9me+l3OPAWpL65us7SWqqGq7a8x8LfCPvpbQm0K/K9Q8B20naKF+/Sh6jYuySNoyIh/NG4i+TEktFY8jvjaR+wCuNVFqZmZmZmZmZLVNabMlb3s9mP+B3eb+bd4GngRPKul4CjJB0CKm6pFSR0g84SdIHwFvAIUBX4CpJpUTZj+sIaShpWdnknBx6mfQtZk05Avg18C9Jc4FXgJOauOanwMN5joepnJSp5kDg4Hzf/wV+WaXfAEn7Fl5/kVQZNT6/HhoRUwDyXkjTSZVgM0jLxIo68f/t3Xm4XVV9//H3hwQIk6CCyqAGKEgBIWrQilNEFJU6VRSUiqgtonXC4lStxVmLWkUcihQjFQFlkioVUAwgIJBAGBUH8FdBRVRkMkzh+/tjryuHk3uTezKd3Jv363nOc/dZe621v3vfdW+Sb9ZaB76VZBrdTKC3t/LjgC+3jan/8ml5VXV3kr2Bz6XbiHwB3f5Pty/mvsZ6/icCz6LbEP1XdHs89cdHVd2UZH/g2LYHE3RJxdvGiP3QtidXgO8DlwHP6OnyELollZcDfwZevZjYJUmSJElaraSqhh2DhizJ+lV1e7pPmzsHOKCqLhl2XCN64nsoXULsKVX122HHNV6PesQ29c59Pz3sMKTl6lUffcFKu9bc8+cwc9dZK+16E4XPRYNwvGgQjheNl2NFg3C8TFwbTcu80bZzmQibcmvFOyLJ9nR7OX11VUomNd9un8S2FvChiZRMkiRJkiRpMjKhJKrqlcOOYXGqatawY5AkSZIkSfcb5qbckiRJkiRJmoBMKEmSJEmSJGkgLnmTVrB1NlxjpW5grInNzQolSZIkTQTOUJIkSZIkSdJATChJkiRJkiRpICaUJEmSJEmSNBATSpIkSZIkSRqIm3JLK9jtv/8dh79ur2GHoQnkR/91+LBDWCpv+q8Thh2CJEmSpJXEGUqSJEmSJEkaiAklSZIkSZIkDcSEkiRJkiRJkgayUhNKSRYmmZ/ksiSXJNm1lW+WZKVuvpFkdpLreuJ51hLqT09y5cqKb1kkOSTJwcuhnyOTbL+Y8/sn2Wy89Vd1SV6Y5N3DjkOSJEmSpFXdyt6Ue0FVzQBIsgfwMeAZVfVrYLnsWpxkSlUtHGf1d1TVCUmeCRwBbLM8YpgsquofllBlf+BK4NfjrD+qJFOr6t6ladvTxyDf91FV1anAqcvShyRJkiRJq4NhLnl7EHAzPHD2T5v1clKS7yb5WZJ/H2mQ5ItJ5ia5KskHesp/meQTSS4B3t2+jpzbpvf9GC4ANm/1pyQ5NMnFSS5P8vr+ymPVSXJckj176s1Osle7v3PbrKzemVmzksxJckKSnyQ5JknauV2SnN9mT12UZIPxxDaWdA5NcmWSK5Ls3crXSPKFdv0zk5yWZK92bk6Sme26s3vaHtTqzASOabO81hmp39o+t93rZUm+P0o8+yc5NclZwPeTrJfkqHavlyZ5Uau3bpJvJLk6yclJLuy5xu1JPpXkMuDJSf6+tZ+f5D9b3IvE3tq+pfV5eZLjemI6vB1PT3JWO//9JI/q+Z4e1r431448K0mSJEmSVicre4bSOknmA9OATYHdxqg3A3gccBdwTZLPVdWvgPdW1R+TTKFLQuxUVZe3Nn+oqscDJNk9yYyqmg+8BvjKEuJ6LnBKO34dcEtV7ZJkbeC8JGcA1VN/rDrHAy8HvpNkLeBZwBuAAM+uqjuTbAMcS5eMod3nDnSzfM4DnpLkotbX3lV1cZIHAQvGum5VXbeE+wP4u/ZcdwY2Bi5Ocg7wFGA6sD3wMODHwFF9bWcAm1fVjgBJNqqqPyV5E3BwVc1t5bSvmwBfBp5eVdclecgYMT0e2Kl9Tz8KnFVVr02yEXBRku+153dzVW2fZEdgfk/79YALq+qfk/w18C7gKVV1T5IvAPsCV/XH3tq+G9iyqu7qKev1OeCrVfXVJK8FDgNe3M5tCjwV2I5uRpOflS5JkiRJWq2s7BlKC6pqRlVtR5fEOXpkRk6f71fVLVV1J3A18OhW/vJ0s40upUvC9O7Xc3zP8ZHAa1riaW/g62PEc2iSn7bzn2hlzwH2a4mvC4GHsuhSuLHq/C/wzJbseR5wTlUtANYEvpzkCuCbfXFfVFXXV9V9dMmS6cBjgN9U1cUAVXVrWxI2ntjG8lTg2KpaWFU3AmcDu7Tyb1bVfVX1W+AHo7S9FtgqyeeSPBe4dQnX+pt279e1+P84Rr0ze849h2522XxgDl3S8VEtvuNaP1cCl/e0Xwic2I6fBTyBLlE2v73fajGxX043u+rvgdGW2z2Z+8fNf7c4RpzSntfVwMNHu7EkB6SbTTd3jHuXJEmSJGnCWtkzlP6iqi5IsjGwySin7+o5XghMTbIlcDCwS1XdnGQ2XdJhxB09xycC/wacBcyrqj+MEcbIHkpvppuV8wS62URvrqrTeysmmd77drQ6rd4cYA+6RNZxrfgg4Ea62UFrAHcu7l7HiHXM6yb5CLAnwMgeVctTe947093XgXSzsF67HLru/Z4FeGlVXdNbYfR841/c2bNvUuhmFL2nv9IYse8JPB14AfDeJI8dIO7e79moAVbVEXT7crH5Qx9co9WRJEmSJGmiGtoeSkm2A6YAYyV7+j2ILgFxS5KH080AGlWb2XQ68EWWvNwN4HBgjXQbhZ8OvCHJmi3ObZOs11d/cXWOp1tm9zTgu61sQ7oZR/cBr6K778W5Btg0yS6t/w2STB3rulX13jbza8Zi+jwX2LvtKbQJXTLlIrpldi9Nt5fSw4FZ/Q1b4m+NqjoReB/dUjWA24ANRrnWj4CntyQgi1ny1ut04M0jM9aSPK6Vn0eXBCLdJ8iNlfj5PrBXkoeNXDPJo0eLPckawCOr6gd0y+Q2BNbv6+98YJ92vC/d85MkSZIkSQxvDyXoZna8uqoWLmEWCgBVdVmSS4GfAL+iSzQszjHAS4AzxtF3Jfkw8E7g2XTLzi5pyY2buH/vnBFHLqbOGXRLpL5VVXe3si8AJybZjy7JdAeLUVV3p9s0+3NJ1qHbP2n3JVy33/uSvK3n/SPplnFdRrcf1Dur6rdJTqRbHnY13XO9BLilr6/Nga+0RAzAyCyg2cCXkixofY/Ef1OSA4CTWpvf0T3XxfkQ8Bng8tbmOuBv6Z7dV5NcTfe9v2qU+Kiqq5O8Dzijtb8H+Ce6Z9cf+xTga0k2pBuHh7U9oXq7fHNr9w665/yaJcQvSZIkSdJqI1WTczVOkoOBDavqX4cdy6ouyfpVdXuSh9LNWnpK209p6No+WGu2Dc23Br4HPKYnWbfK2/yhD643Pu9Zww5DWuHe9F8rZn/6uefPYeaus1ZI3xOZz0WDcLxoEI4XjZdjRYNwvExcG03LvKqa2V8+tD2UVqQkJwNbM/anyOmBvt0+6Wwt4EOrSjKpWRf4QVvmF+CNEymZJEmSJEnSZDQpE0pV9ZJhxzCRVNWsYccwlqq6DVgkEypJkiRJkoZnaJtyS5IkSZIkaWIyoSRJkiRJkqSBTMolb9KqZP2NH7bCNivW5ONmhZIkSZImAmcoSZIkSZIkaSAmlCRJkiRJkjQQE0qSJEmSJEkaiHsoSSvYmrfDrz951rDD0ASxGfDr8x0vAJsdvNuwQ5AkSZI0BmcoSZIkSZIkaSAmlCRJkiRJkjQQE0qSJEmSJEkaiAklSZIkSZIkDcSE0kqWZGGS+UmuSnJZkn9OslTfhyQfTLL7Ys4fmGS/pY/2L/1MT/LKZe1nOcQxK8m3l2N/RybZvh2/LMmPk/wgycwkhy2v60iSJEmSNNn4KW8r34KqmgGQ5GHA14EHAf82aEdV9f4lnP/S0gQ4iunAK+lifYAkU6vq3uV0nZWqqv6h5+3rgH+sqh+293PH289EfgaSJEmSJC0NZygNUVX9DjgAeFM6U5IcmuTiJJcnef1I3STvSnJFm9X08VY2O8le7fjjSa5u7T7Zyg5JcnA7npHkR+38yUke3MrnJPlEkouS/DTJ00YJ9ePA09rMqoOS7J/k1CRnAd9Psl6So1oflyZ5Uet71PtJsmmSc1p/V452zSS7JDm/3e9FSTboO//EJBe0652f5DGtfIdWf3675jYtvu+0vq5MsnfPvc9M8n7gqcB/tXj/MhNqMff2gGewdCNAkiRJkqSJyRlKQ1ZV1yaZAjwMeBFwS1XtkmRt4LwkZwDbtXNPqqo/J3lIbx9JHgq8BNiuqirJRqNc6mjgzVV1dpIP0s2Iels7N7Wqnpjk+a28fxndu4GDq+pv2/X2Bx4P7FRVf0zyUeCsqnptu/ZFSb4H7DvG/fwdcHpVfaTd+7p997MWcDywd1VdnORBwIK+mH4CPK2q7m3L/j4KvBQ4EPhsVR3T+pkCPB/4dVXt2frfsO978MEku7V7nJtkVs/p945xb/Q+g1GetyRJkiRJk5YJpVXLc4CdRmYdARsC29AleL5SVX8GGCWBcQtwJ90Mm28DD9hnqCVQNqqqs1vRV4Fv9lQ5qX2dR7e8bTzO7InjOcALR2ZDAdOARy3mfi4GjkqyJnBKVc3v6/sxwG+q6uJ2v7e2++itsyHw1STbAAWs2covAN6bZAvgpKr6WZIrgE8l+QTw7ao6d5z3uLh7638GD5DkALrZZ+yw2bYDXE6SJEmSpFWfS96GLMlWwELgd0DoZhHNaK8tq+qMJfXR9u95InAC8LfAdwcM4672dSHjTzLe0XMc4KU9cT+qqn7MGPdTVecATwduAGZn6TYO/xDwg6raEXgBXaKHqvo68EK6GU2nJdmtqn5KN5voCuDDbYnbeI11b/3P4AGq6oiqmllVMwe/NUmSJEmSVm0mlIYoySbAl4DDq6qA04E3tJk7JNk2yXrAmcBrkqzbyvuXvK0PbFhVpwEHATv3nq+qW4Cbe/YqehVwNuN3G7DBYs6fDrw5bQpRksf1lC9yP0keDdxYVV8GjqRL9vS6Btg0yS6t3QZJ+hNdG9IlpAD2HylsCbprq+ow4Ft0M6Q2A/5cVV8DDh3leosz1r1JkiRJkrTacsnbyrdOkvl0S7TuBf4b+HQ7dyTdkrNLWgLjJuDFVfXdJDOAuUnuBk4D/qWnzw2AbyWZRjej5u2jXPfVwJdaUupa4DUDxHw5sDDJZcBs4Oa+8x8CPgNcnmQN4Dq6mVKj3g8wC3hHknuA24EHzFCqqrvbxtmfS7IO3Wyj/n2d/p1uydv7gO/0lL8ceFXr+7d0eyvtAhya5D7gHuANA9z7WPcmSZIkSdJqK93EGEkryo6bP6a++cYvDjsMacLZ7ODdAJh7/hxm7jpruMGsgnwuGoTjRYNwvGi8HCsahONl4tpoWuaNtp2LS94kSZIkSZI0EBNKkiRJkiRJGogJJUmSJEmSJA3EhJIkSZIkSZIG4qe8SSvYPevfv7mwtCRuVihJkiRpInCGkiRJkiRJkgZiQkmSJEmSJEkDMaEkSZIkSZKkgbiHkrSC3XbbbfzHxw4ZdhiaQM49e86wQ1jluK+UJEmStGpxhpIkSZIkSZIGYkJJkiRJkiRJAzGhJEmSJEmSpIGYUJIkSZIkSdJAJkVCKcnCJPOTXJbkkiS7tvLNkpywkmOZneS6nnietYT605NcubLiWxZJDklyQ7u3nyU5Kcn2S9nXEr83Sc5fukgX6Wf/JJstj74kSZIkSdIkSSgBC6pqRlXtDLwH+BhAVf26qvZaHhdIMmWA6u+oqhnA24AvLY/rr0L+oz3rbYDjgbOSbDJoJ+P53lTVrksbZJ/9gVETSgN+XyVJkiRJEpMnodTrQcDN8MDZP22WyklJvttm1/z7SIMkX0wyN8lVST7QU/7LJJ9Icgnw7vZ15Nw2ve/HcAGweas/JcmhSS5OcnmS1/dXHqtOkuOS7NlTb3aSvdr9ndtmZfXOzJqVZE6SE5L8JMkxSdLO7ZLk/DZ76qIkG4wnttFU1fHAGcArW99PSHJ2knlJTk+yaSv/qyTf65lBtnXf92aHFsv8dv1tWvnt7WtafFcmuSLJ3ku6z55ntRcwEzim9b9O3/f1ZUmek+SCFts3k6y/hPt5S5KrW6zHjedZSZIkSZI0mUwddgDLyTpJ5gPTgE2B3caoNwN4HHAXcE2Sz1XVr4D3VtUf22yV7yfZqaoub23+UFWPB0iye5IZVTUfeA3wlSXE9VzglHb8OuCWqtolydrAeUnOAKqn/lh1jgdeDnwnyVrAs4A3AAGeXVV3tiTMsXTJE9p97gD8GjgPeEqSi1pfe1fVxUkeBCwY67pVdd0S7g/gEmC7JGsCnwNeVFU3taTPR4DXAscAH6+qk5NMo0tkPqynjwOBz1bVMe3++mcN/R3d925nYGPg4iTnjHWfwA9HGlbVCUneBBxcVXMBWs7pD1X1+CQbAycBu1fVHUneBbw9yccWcz/vBrasqruSbDSOZyRJkiRJ0qQyWRJKC9oSM5I8GTg6yY6j1Pt+Vd3S6l0NPBr4FfDyJAfQPY9Nge2BkYTS8T3tjwRek+TtwN7AE8eI59AkHwW2AJ7cyp4D7NRmzABsCGwD/LSn3Vh1/hf4bEv2PBc4p6oWJNkQODzJDGAhsG1PXxdV1fXtXucD04FbgN9U1cUAVXVrOz/WdceTUBqZEfQYYEfgzJawmQL8JskGwOZVdXK75p3tmr19XAC8N8kWwElV9bO+azwVOLaqFgI3Jjkb2AW4dYz7/CFLNvJ9/Ru67/d5Laa1Wjyj3k9rczndjKdTuD9h+MCH0o2nAwA23XTTcYQjSZIkSdLEMVkSSn9RVRe0WSej7etzV8/xQmBqki2Bg4FdqurmJLPpZjqNuKPn+ETg34CzgHlV9YcxwnhHmxnzZuAo4Al0iZc3V9XpvRWTTO99O1qdVm8OsAddImtkmdVBwI10M3fWAO5c3L2OEeuY103yEWBPgJGE3SgeB8xtfVxVVU/uPdkSSotVVV9PcmG71mlJXl9VZy2pXTPIffYa+b4GOLOqXtF7MsljGeV+mj2BpwMvoEuEPbaq7u2tUFVHAEcAbLbZZrVoF5IkSZIkTVyTbg+lJNvRzSYZK9nT70F0yYVbkjwceN5YFdvsmtOBL7Lk5W4AhwNrJNmjtXtDWxpGkm2TrNdXf3F1jqdbZvc04LutbEO6GUf3Aa9i0aVi/a4BNk2yS+t/gyRTx7puVb23bcA9Y7TOkryUblbVsa3vTdoMMZKsmWSHqroNuD7Ji1v52knW7etnK+DaqjoM+BawU9+lzgX2TrfX0yZ0yZyLlnCvvW4Dxkps/YhuOeBftVjWS7LtWPeTZA3gkVX1A+BddN+D9QeIRZIkSZKkCW+yzFAa2UMJuhknr66qhX3LqkZVVZcluRT4Cd3yt/OW0OQY4CV0m1Evqe9K8mHgncCz6ZZjXdI2jr4JeHFfkyMXU+cM4L+Bb1XV3a3sC8CJSfajSzLdwWJU1d1tL6DPJVmHbv+k3Zdw3X4HJfl7YD3gSmC3qroJ/rIB9mFtKd5U4DPAVXTJrv9M8kHgHuBlwH09fb4ceFWSe4DfAh/tu+bJdEsHL6Pbc+qdVfXbljwcj9nAl5Is4P4liCPP5KYk+wPHtiWFAO+rqp+OcT8/Bb7WygIcVlV/GmcckiRJkiRNCqlyNc4gkhwMbFhV/zrsWDQxbLbZZnXAAQcMOwxpQjvoPYcMO4RVztzz5zBz11nDDkMThONFg3C8aLwcKxqE42Xi2mha5lXVzP7yyTJDaaVIcjKwNWN/ipwkSZIkSdKkZ0JpAFX1kmHHIEmSJEmSNGyTblNuSZIkSZIkrVjOUJJWsA022MD9XzRuri1f1Nzz5ww7BEmSJEl9nKEkSZIkSZKkgZhQkiRJkiRJ0kBMKEmSJEmSJGkgJpQkSZIkSZI0EDflllawe++9ntNPfeKww9AEcvqpw45gVXTRsAOQJEmS1MMZSpIkSZIkSRqICSVJkiRJkiQNxISSJEmSJEmSBjIpE0pJHpHkuCS/SDIvyWlJtk0yPcmVy/E6H0yyezt+WpKrksxPsnmSE5ax7/WT/GfPPcxJ8qSluYckBybZb1niaf3sn+SmJJcm+VmS05Psugz9nb+E86cl2Whp++/p58VJtl/WfiRJkiRJUmfSbcqdJMDJwFerap9WtjPwcOBXy/NaVfX+nrf7Ah+rqq+193uNt58kU6vq3r7iI4HrgG2q6r4kWwLbAzcuRZxfGrTNYhxfVW8CSPJM4KQkz6yqHy9FXItNRlXV85cyxn4vBr4NXN1/YoxnL0mSJEmSFmMyzlB6JnBPbxKlqi6rqnN7K7WZPucmuaS9dm3lmyY5p800urLNPJqSZHZ7f0WSg1rd2Un2SvIPwMuBDyU5pncWUWt7aJKLk1ye5PWtfFa7/qn0JTqSbA08CXhfVd3X7uG6qvpOqzIlyZfbjKgzkqzT2v1ju85lSU5Msm4rPyTJwe14TpJPJLkoyU+TPK2V79DK5rc4t1nSg66qHwBHAAeMxJ3ku21G1blJtmvlD09ycovrsp5nfftYz7yV/zLJxu347e3clUne1vM9/PFoz6LnWe4KvBA4tPW/dXsGn0kyF3hrkickObvFfXqSTZdwPy9rcVyW5JwlPSdJkiRJkiabSTdDCdgRmDeOer8Dnl1Vd7bkybHATOCVwOlV9ZEkU4B1gRnA5lW1I0D/MqyqOjLJU4FvV9UJSab3nH4dcEtV7ZJkbeC8JGe0c48Hdqyq6/pi2wGYX1ULx4h9G+AVVfWPSb4BvBT4GnBSVX25xfjhdu3PjdJ+alU9McnzgX8DdgcOBD5bVcckWQuYMtaD63MJ8Pp2fARwYFX9LMmTgC8AuwGHAWdX1UvaM12/r4/RnvlfJHkC8Bq6JFuAC5OcDdy8mGcBQFWd35J2366qE1p/AGtV1cwkawJnAy+qqpuS7A18BHjtYu7n/cAeVXVD/1iQJEmSJGl1MBkTSuO1JnB4khnAQmDbVn4xcFRLNJxSVfOTXAtsleRzwHeAM0brcAzPAXZKMrIEbkO6JMjdwEWjJJPG47qqmt+O5wHT2/GOLZG0EV3S5vQx2p80StsLgPcm2YIuMfWzccYS6PZ8AnYFvtkSNgBrt6+7AfsBtCTZLX19LPLM+84/FTi5qu5o1zoJeBpwKmM/iyU5vn19DF0S8swW9xTgN0u4n/OA2S2BdRKjSHIAbebWVlutO1oVSZIkSZImrMm45O0q4AnjqHcQ3X5EO9PNTFoLoKrOAZ4O3ECXNNivqm5u9ebQzeQ5coB4Ary5qma015ZVNZKQumMx97Bzm60zmrt6jhdyf2JwNvCmqnos8AFg2hLa/6VtVX2dbmnYAuC0JLsl+ae2TGx+ks3G6OtxwI/pxtKfeu5zRlX99RhtHmC0Zz6edn338oD7GYeRZx/gqp6YH1tVz2Ex91NVBwLvAx4JzEvy0FHu6YiqmllVMwe4F0mSJEmSJoTJmFA6C1i7zRABIMlOI/vy9NgQ+E3bo+hVtCVeSR4N3NiWjh0JPL7t47NGVZ1Il0h4/ADxnA68oc2+Id2nza23uAZV9QtgLvCBtOkxbb+gPZdwrQ3oZtesSbdJ+Lgl2Qq4tqoOA74F7FRVn+9Jpvx6lDbPoJuF8+WquhW4LsnL2rmk2wwd4PvAG1r5lCQb9vWzyDPvu9S5wIuTrNue3Uta2XjdRvdsRnMNsEmSJ7dY1kyyw+LuJ8nWVXVh25T9JrrEkiRJkiRJq41Jl1CqqqJLOOye5BdJrgI+Bvy2r+oXgFcnuQzYjvtnrMwCLktyKbA38Flgc2BOkvl0+/O8Z4CQjqTbdPuSdBt1/yfjm0XzD3SfTPfz1m423b5Pi/OvwIV0S7J+MkCM0G0qfmW7xx2Bo8eot3ebsfRT4F+Al/Z8wtu+wOvaM70KeFErfyvwzCRX0C1L276vz1ks+sz/oqouobv/i9r9HVlVlw5wb8cB70hyaboNz3v7vpvuE/k+0eKeT7fUbXH3c2i6zdmvBM4HLhsgFkmSJEmSJrx0+RdJK8rWW69XH/v4DsMOQ5rQ9njhRcMOYZUz9/w5zNx11rDD0ATheNEgHC8aL8eKBuF4mbg2mpZ5o23nMulmKEmSJEmSJGnFMqEkSZIkSZKkgZhQkiRJkiRJ0kBMKEmSJEmSJGkg4/m0MUnLYOrULdxQWOPmZoWLmnv+nGGHIEmSJKmPM5QkSZIkSZI0EBNKkiRJkiRJGogJJUmSJEmSJA3EhJIkSZIkSZIG4qbc0gr2q3uLp//P6cMOQxOJ42VRPpPR+Vw0CMeLxuGcF+wx7BAkSROEM5QkSZIkSZI0EBNKkiRJkiRJGogJJUmSJEmSJA3EhJImjCSV5Gs976cmuSnJt9v7/ZMc3o73SDK/vW5Pck07PjrJukmOSXJFkiuT/DDJ+kl+kGSPvmu+LckXk0xv1/9wz7mNk9wzck1JkiRJklYXJpQ0kdwB7Jhknfb+2cANo1WsqtOrakZVzQDmAvu29/sBbwVurKrHVtWOwOuAe4BjgX36utqnlQNcB+zZc+5lwFXLfluSJEmSJE0sJpQ00ZzG/UmdV3B/smcQm9KTiKqqa6rqLuAEYM8kawEkmQ5sBpzbqv4Z+HGSme393sA3luL6kiRJkiRNaCaUNNEcB+yTZBqwE3DhUvRxFPCuJBck+XCSbQCq6o/ARcDzWr19gG9UVY1y/UcCC4FfL+V9SJIkSZI0YZlQ0oRSVZcD0+lmJ522lH3MB7YCDgUeAlyc5K/b6d5lb73L3UZ8l26p3T7A8WNdI8kBSeYmmbs0MUqSJEmStCozoaSJ6FTgkyzdcjcAqur2qjqpqt4IfA14fjv1LeBZSR4PrFtV8/ra3Q3MA/6ZboncWP0fUVUzq2rmWHUkSZIkSZqopg47AGkpHAX8qaquSDJr0MZJngJcXVU3t/2StgfmQJdoSvKDdo2xElafAs6uqj8mWYrwJUmSJEma2EwoacKpquuBw8Y4vX+SF/e8/5tR6mwNfDFdNmgN4DvAiT3njwVOZtFPfBu5/lX46W6SJEmSpNWYCSVNGFW1/ihlc7h/dtFsYPYoTWf1tTkaOHox1zkFSF/ZL4EdR6k71jUlSZIkSZq03ENJkiRJkiRJAzGhJEmSJEmSpIGYUJIkSZIkSdJATChJkiRJkiRpIG7KLa1gj5waznnBHsMOQxPE3PPnMHPXWcMOY5XiMxmdz0WDcLxIkqTlzRlKkiRJkiRJGogJJUmSJEmSJA3EhJIkSZIkSZIGkqoadgzSpLbeI7as7V71gWGHIUmStEzO+vB+ww5Bqxj3Z9MgHC8T10bTMq+qZvaXO0NJkiRJkiRJAzGhJEmSJEmSpIGYUJIkSZIkSdJATChJkiRJkiRpICaUVjNJFiaZn+SyJJck2bWVT0+yoJ27OsnRSdZs5/ZPcvgofR2S5M9JHtZTdnvPcSX5VM/7g5McMo4Yn5dkbovj0pE+2vUOXqYH8MDrnN9zfGiSq9rXA5O466QkSZIkSWOYOuwAtNItqKoZAEn2AD4GPKOd+0VVzUgyBTgTeDlwzBL6+z3wz8C7Rjl3F/B3ST5WVb8fT3BJdgQOB/asqp+0WA4YT9tBVdWuPW8PAB5SVQsH7SfJ1Kq6d/lFJkmSJEnSqs0ZSqu3BwE39xe2pMpFwOb955LsmeSCJBu3oqOAvZM8ZJT+7wWOAA4apZ8XJLmwzUD6XpKHt1PvBD5SVT8ZiaWqvjhK+39McnGbaXViknVb+cuSXNnKz2llOyS5qM2+ujzJNq389vb1VGB9YF6SvXtnQiXZOsl3k8xLcm6S7Vr57CRfSnIh8O9jPF9JkiRJkiYlE0qrn3VaYuUnwJHAh/orJJkGPAn4bl/5S4B3A8/vmXF0O11S6a1jXO/zwL5JNuwr/yHwN1X1OOA4ukQSwI7AvHHcx0lVtUtV7Qz8GHhdK38/sEcrf2ErOxD4bJuZNRO4vrejqnohbeZWVR3fd50jgDdX1ROAg4Ev9JzbAti1qt4+jnglSZIkSZo0XPK2+uld8vZk4Oi2zAxg6yTzgS2B71TV5T3tdqNLxjynqm7t6/MwYH6ST/ZfrKpuTXI08BZgQc+pLYDjk2wKrAVcN+B97Jjkw8BGdLOLTm/l5wGzk3wDOKmVXQC8N8kWdImon43nAknWB3YFvplkpHjtnirfHGuJXJIDaEv11n349HHekiRJkiRJE4MzlFZjVXUBsDGwSSv6RUs2bQ08IckLe6r/AtgA2HaUfv4EfB34pzEu9Rm6GUTr9ZR9Dji8qh4LvB6Y1sqvAp4wjvBnA29q7T8w0r6qDgTeBzySbgnbQ6vq63SzlRYApyXZbRz9Q/fz8ac2c2nk9dc95+8Yq2FVHVFVM6tq5jivJUmSJEnShGFCaTXW9gOaAvyht7wtZ3s38J6e4v8HvJRuRtMOo3T3abrE0CKz3qrqj8A3uH9ZGsCGwA3t+NU95YcC/5Jk2xbjGkkOHOV6GwC/aZ9Et2/PPW1dVRdW1fuBm4BHJtkKuLaqDgO+Bew0Sn+LaDOxrkvystZ3kuw8nraSJEmSJE1mJpRWPyN7KM0HjgdePcayrVOAdZM8baSgbZS9L90SsK17K7ck1Mk8cElYr0/RzYYacUjrZx7dJ8WN9HM58Dbg2CQ/Bq4Ethqlv38FLqRb4vaTnvJDk1yR5ErgfOAyuk+ru7Ld847A0WPEOJp9gdcluYxu9tSLBmgrSZIkSdKklKoadgzSpLbeI7as7V71gWGHIUmStEzO+vB+ww5Bq5i5589h5q6zhh2GJgjHy8S10bTMG207F2coSZIkSZIkaSAmlCRJkiRJkjQQE0qSJEmSJEkaiAklSZIkSZIkDWSRj3iXtHxtseFabmKpcXOzwkX5TEbnc9EgHC8ahONFkjQezlCSJEmSJEnSQEwoSZIkSZIkaSAmlCRJkiRJkjQQ91CSVrC1b/8/bvnEY4cdhiaIbYBbzh12FKsWn8nofC4ahONFg1hVxsuG77pi2CFIkhbDGUqSJEmSJEkaiAklSZIkSZIkDcSEkiRJkiRJkgZiQkmSJEmSJEkDMaGkCS1JJflaz/upSW5K8u32fv8kh4/S7vZRyqa3/t7cU3Z4kv3b8ewkNyRZu73fOMkvl/9dSZIkSZK0ajOhpInuDmDHJOu0988GbliG/n4HvDXJWmOcXwi8dhn6lyRJkiRpwjOhpMngNGDPdvwK4NjxNmyzjC5IMtL+JuD7wKvHaPIZ4KAkU5cyVkmSJEmSJjwTSpoMjgP2STIN2Am4cDyNkjwc+A7w/qr6Ts+pTwAHJ5kySrP/A34IvGrZQpYkSZIkaeIyoaQJr6ouB6bTzU46bZzN1qSbifTOqjqzr79r6ZJSrxyj7ceAd7CYn58kBySZm2TuOOORJEmSJGnCMKGkyeJU4JOMf7nbvcA8YI8xzn8UeBeQ/hNV9TNgPvDysTqvqiOqamZVzRxnPJIkSZIkTRgmlDRZHAV8oKquGGf9ottce7sk71rkZNVPgKuBF4zR/iPAwUsTqCRJkiRJE50JJU0KVXV9VR02xun9k1zf89qitVlIt0xutyRvHKXdR4AtxrjeVcAlyyN2SZIkSZImGj+pShNaVa0/StkcYE47ng3MHqXp+u38XTxw2duOPf1cRk/Star277vO3y1l2JIkSZIkTWjOUJIkSZIkSdJATChJkiRJkiRpICaUJEmSJEmSNBD3UJJWsLvWfxQbvmu8Hz6n1d3c8+cwc9dZww5jleIzGZ3PRYNwvGgQjhdJ0ng4Q0mSJEmSJEkDMaEkSZIkSZKkgZhQkiRJkiRJ0kBMKEmSJEmSJGkgbsotrWA3LLiB5x/xlGGHoYnkymEHsArymYzO56JBOF40iNV8vJx2wHnDDkGSVnnOUJIkSZIkSdJATChJkiRJkiRpICaUJEmSJEmSNBATSquZJAuTzE9yVZLLkvxzkgkxDpJMT7LcVvQn+WCS3dvx09ozmZ9k8yQnLK/rSJIkSZI02bgp9+pnQVXNAEjyMODrwIOAfxtmUMNQVe/vebsv8LGq+lp7v9d4+0kytaruXa7BSZIkSZK0CpsQM1O0YlTV74ADgDels3+Sw0fOJ/l2klnt+PYkh7ZZPN9L8sQkc5Jcm+SFrc7+SU5JcmaSXyZ5U5K3J7k0yY+SPCTJ1kku6bnGNr3ve8r/ql3nsiSXJNm67/z0JOe2c5ck2bWVb5rknDbT6Mo282hKktnt/RVJDmp1ZyfZK8k/AC8HPpTkmN6ZUK3toUkuTnJ5kte38lnt+qcCVy/Hb4skSZIkSas8Zyit5qrq2iRTgIctoep6wFlV9Y4kJwMfBp4NbA98FTi11dsReBwwDfg58K6qelyS/wD2q6rPJLklyYyqmg+8BvjKKNc7Bvh4VZ2cZBpd8rM3xt8Bz66qO5NsAxwLzAReCZxeVR9p97UuMAPYvKp2BEiyUd8zODLJU4FvV9UJSab3nH4dcEtV7ZJkbeC8JGe0c48Hdqyq65bw7CRJkiRJmlRMKGm87ga+246vAO6qqnuSXAFM76n3g6q6DbgtyS3A//S02akdHwm8Jsnbgb2BJ/ZeKMkGdAmgkwGq6s5W3lttTeDwJDOAhcC2rfxi4KgkawKnVNX8JNcCWyX5HPAd4AzG7znATklGlsBtCGzTnsdFYyWTkhxAN/uL9R653gCXkyRJkiRp1eeSt9Vckq3oEjK/A+7lgWNiWs/xPVVV7fg+4C6AqrqPByYm7+o5vq/nfW+9E4HnAX8LzKuqPyxF6AcBNwI7081MWqvFcw7wdOAGYHaS/arq5lZvDnAgXUJrvAK8uapmtNeWVTWSkLpjrEZVdURVzayqmQPelyRJkiRJqzwTSquxJJsAXwIOb8miXwIzkqyR5JH0zRxaXtqMo9OBLzLKcrc2w+n6JC9uca6dZN2+ahsCv2kJrVcBU1rdRwM3VtWX6RJHj0+yMbBGVZ0IvI9uqdp4nQ68oc14Ism2SZxyJEmSJElarbnkbfWzTpL5dEvG7gX+G/h0O3cecB3dJtM/BhbZLHs5OgZ4CWMvP3sV8J9JPgjcA7yMbpbTiC8AJybZj24p3shsoVnAO5LcA9wO7AdsDnwlyUgC9T0DxHkk3ZK+S9KtubsJePEA7SVJkiRJmnRy/yomaeVJcjCwYVX967BjWdHWf9T6tfM7dh52GJIkSRqn0w44b9ghTAhzz5/DzF1nDTsMTRCOl4lro2mZN9p2Ls5Q0krXPiVua2C3YcciSZIkSZIGZ0JJK11VvWTYMUiSJEmSpKXnptySJEmSJEkaiAklSZIkSZIkDcQlb9IKtvk6m7uxo8bNzQoX5TMZnc9Fg3C8aBCOF0nSeDhDSZIkSZIkSQMxoSRJkiRJkqSBmFCSJEmSJEnSQNxDSVrRfv1r5j/7GcOOQhPEVGD+sINYxfhMRudz0SAcLxqE40XjNdpYmXHm2UOIRNIwOENJkiRJkiRJAzGhJEmSJEmSpIGYUJIkSZIkSdJATChJkiRJkiRpICaUtEpLUkm+1vN+apKbkny7vd8/yeFjtB2p+/G+8jlJrklyWZKLk8zoO/+ZJDckWaOnbP8Wy+49ZS9uZXstp9uVJEmSJGlCMKGkVd0dwI5J1mnvnw3cMM62zwZ+CrwsSfrO7VtVOwNfAA4dKWxJpJcAvwL6P5rtCmCfnvevAC4bZyySJEmSJE0aJpQ0EZwG7NmOXwEcO852rwA+C/wf8OQx6lwAbN7zfhZwFfDF1r7XucATk6yZZH3gr/BTdSVJkiRJqyETSpoIjgP2STIN2Am4cEkNWt3dgf+hS0D1J4dGPBc4pef9SMLqZGDPJGv2nCvge8AewIuAUwe6C0mSJEmSJgkTSlrlVdXlwHS6ZM9p42z2t8APqmoBcCLw4iRTes4fk+Q64L3A5wGSrAU8Hzilqm6lS1zt0dfvcXTL3vZhMTOlkhyQZG6SueOMV5IkSZKkCcOEkiaKU4FPMthyt92T/BKYBzwU2K3n/L7AVsBXgc+1sj2AjYArWrun0jezqaouAh4LbFxVPx3r4lV1RFXNrKqZ44xXkiRJkqQJY+qwA5DG6SjgT1V1RZJZi6uY5EHA04BHVtVdrew1dMmhM0fqVVUl+VfgF0m2a+f/oaqObW3WA65Lsm7fJd4N3Llc7kqSJEmSpAnIGUqaEKrq+qo6bIzT+ye5fuRF9yltZ40kk5pvAS9IsnZfvwuATwHvottP6Ts95+4Afgi8oK/N/1bVD5b5piRJkiRJmqBSVcOOQZrUHrPBBnXE4x4/7DAkSZKkFW7GmWcPOwStouaeP4eZu84adhhaChtNy7zRtnNxhpIkSZIkSZIGYkJJkiRJkiRJAzGhJEmSJEmSpIGYUJIkSZIkSdJApg47AGnS22wzNyfUuLlZ4aJ8JqPzuWgQjhcNwvGi8XKsSKs3ZyhJkiRJkiRpICaUJEmSJEmSNBATSpIkSZIkSRpIqmrYMUiT2qMesU29c99PDzsMSZIkSdKQveqjLxh2CAPbaFrmVdXM/nJnKEmSJEmSJGkgJpQkSZIkSZI0EBNKkiRJkiRJGogJJUmSJEmSJA3EhNJqJsnCJPOTXJbkkiS7tvLpSRa0c1cnOTrJmu3c/kkOH6WvQ5L8OcnDespu7zmuJJ/qeX9wkkPa8ewke40R4xOTnJPkmiSXJjkyybpjxbEMz+K0JBu147ck+XGSY5K8MMm7l9d1JEmSJEmabEworX4WVNWMqtoZeA/wsZ5zv6iqGcBjgS2Al4+jv98D/zzGubuAv0uy8XiDS/Jw4JvAu6rqMVX1OOC7wAbj7WO8qur5VfWn9vaNwLOrat+qOrWqPj5AzFOXd2ySJEmSJK3KTCit3h4E3NxfWFULgYuAzfvPJdkzyQU9SaKjgL2TPGSU/u8FjgAOGuP6uyeZm+SnSf62lf0T8NWquqAnnhOq6sa+OF6Q5MI2g+l7LRFFkme0WVbz27kNkmzaZjzNT3Jlkqe1ur9MsnGSLwFbAf+b5KDemVBJNklyYpKL2+sprfyQJP+d5Dzgv8e4P0mSJEmSJiUTSqufdVpi5SfAkcCH+iskmQY8iW5mUG/5S4B3A8+vqt+34tvpkkpvHeN6nwf2TbLhKOemA08E9gS+1K67IzBvHPfxQ+Bv2gym44B3tvKDgX9qM62eBiwAXgmc3sp2Bub3dlRVBwK/Bp5ZVf/Rd53PAv9RVbsAL6V7ZiO2B3avqleMI15JkiRJkiYNl+qsfha0xApJngwcnWTHdm7rJPOBLYHvVNXlPe12A2YCz6mqW/v6PAyYn+ST/RerqluTHA28hS650+sbVXUf8LMk1wLbDXAfWwDHJ9kUWAu4rpWfB3w6yTHASVV1fZKLgaPanlCnVNX8Aa6zO7B9kpH3D0qyfjs+tar67wmAJAcABwA88uF/NcDlJEmSJEla9TlDaTXWlpVtDGzSikb2UNoaeEKSF/ZU/wXdPkbbjtLPn4Cv0y1XG81ngNcB6/U3HeX9VcATxhH+54DDq+qxwOuBaS2WjwP/AKwDnJdku6o6B3g6cAMwO8l+4+h/xBp0M6FmtNfmVTWy8fgdYzWqqiOqamZVzRzgWpIkSZIkTQgmlFZjSbYDpgB/6C1vy9neTbdp94j/R7fk6+gkO4zS3afpEjuLzHqrqj8C36BLKvV6WZI1kmxNt4fRNcDhwKuTPKknzr8b2SOpx4Z0CSKAV/fU3bqqrqiqTwAXA9sleTRwY1V9mW7J2uNHiX8sZwBv7ul/xgBtJUmSJEmalEworX5G9lCaDxwPvLptwt3vFGDdkQ2sAarqJ8C+wDdbEoiec78HTgbWHuO6n6KbDdXr/+g2//5f4MCqurNtvr0P8Mkk1yT5MbAHcFtf20NaHPPoPmluxNvaxtuXA/e0vmcBlyW5FNibbl+k8XoLMDPJ5UmuBg4coK0kSZIkSZNSqvpXHUlanh71iG3qnft+ethhSJIkSZKG7FUffcGwQxjYRtMyb7TtXJyhJEmSJEmSpIGYUJIkSZIkSdJATChJkiRJkiRpICaUJEmSJEmSNJBFPuJd0vK1zoZrTMiN1zQcc8+fw8xdZw07jFWKz2R0PhcNwvGiQTheNF6OFQ3C8TL5OENJkiRJkiRJA0lVDTsGaVJLchtwzbDj0ISxMfD7YQexivGZjM7nokE4XjQIx4vGy7GiQTheJq5HV9Um/YUueZNWvGuqauawg9DEkGSu4+WBfCaj87loEI4XDcLxovFyrGgQjpfJxyVvkiRJkiRJGogJJUmSJEmSJA3EhJK04h0x7AA0oTheFuUzGZ3PRYNwvGgQjheNl2NFg3C8TDJuyi1JkiRJkqSBOENJkiRJkiRJAzGhJA0oyXOTXJPk50nePcr5tZMc385fmGR6z7n3tPJrkuwx3j41MS3tWEkyPcmCJPPb60s9bZ6Q5IrW5rAkWYm3tFwsw3PZt+eZzE9yX5IZ7dyc1ufIuYet3LtaduN4Lk9PckmSe5Ps1Xfu1Ul+1l6v7imf8ONFi1rGsbKw5+fk1J7yLdvP28/bz99aK+NetOKNY7y8PcnVSS5P8v0kj+455++W1cwyjhd/v6xGxjFWDmy/J+Yn+WGS7XvO+W+iyaKqfPnyNc4XMAX4BbAVsBZwGbB9X503Al9qx/sAx7fj7Vv9tYEtWz9TxtOnr4n3WsaxMh24cox+LwL+Bgjwv8Dzhn2vK+u59NV5LPCLnvdzgJnDvr8V/FymAzsBRwN79ZQ/BLi2fX1wO37wZBgvvpbvWGnnbh+j328A+7TjLwFvGPa9+lpp4+WZwLrt+A09fxb5u2U1ey3LeGnv/f2ymrzGOVYe1HP8QuC77dh/E02ilzOUpME8Efh5VV1bVXcDxwEv6qvzIuCr7fgE4Fntf+5eBBxXVXdV1XXAz1t/4+lTE8+yjJVRJdmU7g/nH1X3J/LRwIuXe+Qr1vJ6Lq9obSeLJT6XqvplVV0O3NfXdg/gzKr6Y1XdDJwJPHeSjBctalnGyqjaz9dudD9v0P38vXi5RaxhGs94+UFV/bm9/RGwRTv2d8vqZ1nGy6j8/TJpjWes3Nrzdj1gZPNm/000iZhQkgazOfCrnvfXt7JR61TVvcAtwEMX03Y8fWriWZaxArBlkkuTnJ3kaT31r19Cn6u6ZX0uI/YGju0r+0qbVv2vE3D5xbL8Hljc75aJPl60qGX9M2NakrlJfpTkxa3socCf2s/b0vSpVdeg4+V1dDOOFtfW3y2T17KMF/D3y+pkXGMlyT8l+QXw78BbltDWfxNNQFOHHYAkaRG/AR5VVX9I8gTglCQ7DDuoVUWSJwF/rqore4r3raobkmwAnAi8iu5/zSU90KPbz8pWwFlJrqBL2mo1l+TvgZnAM4Ydi1Z9Y4wXf7/oAarq88Dnk7wSeB/w6iU00QTjDCVpMDcAj+x5v0UrG7VOkqnAhsAfFtN2PH1q4lnqsdKmAP8BoKrm0a0n37bV751aPhHHyrL8DI3Yh77ZSVV1Q/t6G/B1umnTE8my/B5Y3O+WiT5etKhl+jOj52flWrq9xx5H9/O1Uft5G7hPrdLGNV6S7A68F3hhVd21hLb+bpm8lmW8+Ptl9TLon0XHcf9SR/9NNImYUJIGczGwTfu0irXo/mF7al+dU7k/+74XcFbbY+BUYJ90n2C1JbAN3aaW4+lTE89Sj5UkmySZAtD+l28b4Nqq+g1wa5K/aUu69gO+tTJuZjlalp8hkqwBvJye/ZOSTE2ycTteE/hb4EomlmX5PXA68JwkD07yYOA5wOmTZLxoUUs9VtoYWbsdbww8Bbi6/Xz9gO7nDbqfP8fK5LDE8ZLkccB/0iUHftdzyt8tq5+lHi/+flntjGesbNPzdk/gZ+3YfxNNJsPeFdyXr4n2Ap4P/JRu1sh7W9kH6f5gBZgGfJNug7mLgK162r63tbuGnk9EGa1PXxP/tbRjBXgpcBUwH7gEeEFPnzPpkiW/AA4HMuz7XFnPpZ2bBfyor7/1gHnA5e25fRaYMuz7XAHPZRe6/QTuoPsf36t62r62Pa+fA6+ZTOPF1/IbK8CuwBV0n5xzBfC6nj63aj9vP28/f2sP+z59rbTx8j3gxvZnznzg1J62/m5ZzV5LO178/bL6vcYxVj7L/X+f/QGwQ09b/000SV5p3zhJkiRJkiRpXFzyJkmSJEmSpIGYUJIkSZIkSdJATChJkiRJkiRpICaUJEmSJEmSNBATSpIkSZIkSRqICSVJkqRJLMkhSX4/xrnZSeau7JiWRpJfJvnkSrzehHk2kiQNw9RhByBJkiSNw0uAPww7CEmS1DGhJEmSpFVeVV067BgkSdL9XPImSZIkAJJsmuSoJNcmWZDkp0k+nGStnjrTk1SSfZJ8JcmtSa5P8vft/DuT/DrJTUk+kWSNnraHJPl9kiclmduu8cMkWyZ5WJJTktye5MdJduuL7QFL3kaWpCV5dpLLk9zR+tqhr92DkxzXzv86ybuSfDLJL5fi+cxI8v0kf05yc5Jjkjy8r857kvw8yZ1Jbkzy3SSPaOfWbNf+vyR3tXhOHnm+STZKcmQrv7PV+/KgcUqStDI4Q0mSJGk1kGS0v/el7/3GwB+BtwM3A9sChwCbAK/vq/sJ4BjgpcBrga8meRzw6Pb+CcCHgUuB43rarQscAfw7cAdwGPDfwF3A/wJfAN4JfDPJI6vqz4u5rUcBhwIfARYAnwSOT/LYqqpWZzbwVOCtwG+Bg9p9LVxMv4tIsgkwB/gx8EpgfeDjwJlJZlbV3Un2A/4FeBdwFfBQYDdgvdbNe4B9gXcD1wGPAJ4PTGnnPw3s2mL8LfBI4OmDxClJ0spiQkmSJGnyeyhwzxjn5o0cVNUVwMEj75OcR5f0OSrJm6vq7p52Z1XVv7R6FwJ7AS8EtquqhcB3k7yIbu+j3oTSOsBbqurs1nYz4PPAv1XVJ1vZ9XQJmWfQJZnG8hDgKVX1s9ZuDeBk4DHAT5Ls2GJ6eVV9s9X5PvAr4PbF9Duaf25f96iqW1tfPwN+RJdUOxZ4InBGVX2hp91JPcdPBL5eVV/tKftG3/nPV9XxPWVfGzBOSZJWCpe8SZIkTX63ALuM8vp2b6V03pbk6iQL6JJQxwBr080G6vX9kYOWYLkJOLslk0b8HNi8r93dwLl9dQDOGqWsv22/X44kk5qr29ct2teZ7ev/9MS6APjeEvodzUiy6Naevi4Efkk3AwpgPvD8JB9I8sQkU/r6mA/s35YF7pSkf4bYfOAdSd6YZNuliFGSpJXGhJIkSdLkd29Vze1/seinpr2NbtnYycCL6JIo/9TOTeur+6e+93ePUdbf7raquq+vzgP665kJ1d+232jX6233iHa9O/vq3bSEfkezKXDjKOU30s2UAjiKbsnby4ELgRvbHlQjiaUP083GeiNwGfCrJG/t6etNwCnA+4FrkvwsyT5LEaskSSucCSVJkiSNeBlwQlW9t6rOqKqL6Za8TVS/BTZI0p+Y2mQp+voN8LBRyh9Ot+8UVXVfVf1HVf013YyuT9Ltm/SP7fydVfX+qppOt4/T8cBnkjy3nf9TVb2lqh4B7EyXlDomyfZLEa8kSSuUCSVJkiSNWIduc+xe+w4jkOVkbvv6wpGCJOsAz16Kvi4E9kiyQU9fuwDTgR/2V66qX1XVx+mW7y2SEGpL9Q6me96jnb8ceAfd39e3W4p4JUlaodyUW5IkSSPOBN7SNtn+BV0y6a+GG9LSq6ork/wP8MWWCPot3SfY/Rm4b7GNF/Vp4A3A6Uk+wf2f8nYFcCJAkv+km630I7p9q54JbEP3qW8kOZluE/RL6T6Vbi+6v4+f087/kG654ZVA0c1sugO4aPC7lyRpxTKhJEmSpBEfpFsO9uH2/iTgLfRsaj0B7Q98ETiM7pPdPg9cS7cp+bhV1U1Jngl8iu4T3e4GTgMO6tnz6QK6JNDr6fZx+jnwj1V1Sjt/PrA39888uhp4advPaqT9/nSznhbSJZ6eV1XXDxKrJEkrQ6pq2DFIkiRJK0WSqXQzgC6sqlcPOx5JkiYqZyhJkiRp0kryMmAzuqVpD6KbQbQNsN8w45IkaaIzoSRJkqTJ7A7gNXR7QU2hSyy9oKrcl0iSpGXgkjdJkiRJkiQNZI1hByBJkiRJkqSJxYSSJEmSJEmSBmJCSZIkSZIkSQMxoSRJkiRJkqSBmFCSJEmSJEnSQEwoSZIkSZIkaSD/H4lb8R9sJveyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1224x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_dims = (17, 10)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.barplot(y=list(hamming_loss.keys()), x=list(hamming_loss.values()), palette='tab10',)\n",
    "plt.title('Average hamming loss per model', fontdict ={'size': 20})\n",
    "plt.ylabel('Model', fontdict ={'size': 15})\n",
    "plt.xlabel('Hamming losss',fontdict ={'size': 15})\n",
    "ax.set_facecolor(\"aliceblue\") #setting background color\n",
    "plt.xticks([0, 0.05, 0.075,0.1,0.15,0.2, 0.25, 0.3])\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(axis = 'x')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
